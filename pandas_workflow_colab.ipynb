{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Workflow com LlamaIndex Workflows\n",
        "\n",
        ">Este notebook demonstra como criar um sistema de análise de dados usando LlamaIndex, Pandas e Groq para consultas em linguagem natural.\n",
        "\n",
        "\n",
        "## Sobre a Atualização do LlamaIndex\n",
        "\n",
        "O **LlamaIndex** descontinuou o módulo **QueryPipeline** em favor de uma nova abordagem chamada **Workflows**.\n",
        "Essa mudança foi implementada na versão `0.11` do LlamaIndex, com o objetivo de oferecer uma arquitetura mais\n",
        "flexível e escalável para a construção de aplicações de IA generativa.\n",
        "\n",
        "### Por que o QueryPipeline foi descontinuado?\n",
        "O QueryPipeline era uma API declarativa útil para orquestrar consultas simples a avançadas sobre os dados.\n",
        "Porém, ele se mostrou limitado para cenários mais dinâmicos. Por isso, os **Workflows** foram introduzidos,\n",
        "trazendo uma arquitetura orientada a eventos para fluxos de trabalho mais sofisticados.\n",
        "\n",
        "### O que são Workflows?\n",
        "Workflows permitem orquestrar etapas personalizadas de forma assíncrona e condicional, facilitando\n",
        "integrações complexas e manipulação de dados em tempo real.\n",
        "\n",
        "**Documentação oficial:** [docs.llamaindex.ai](https://docs.llamaindex.ai)\n",
        "\n"
      ],
      "metadata": {
        "id": "3pzznnjN3W-Z"
      },
      "id": "3pzznnjN3W-Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Código:\n"
      ],
      "metadata": {
        "id": "KYxQbJBGAjb7"
      },
      "id": "KYxQbJBGAjb7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 Instalar Dependências:"
      ],
      "metadata": {
        "id": "ne3hDRwyAlhT"
      },
      "id": "ne3hDRwyAlhT"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eaa06244",
      "metadata": {
        "id": "eaa06244"
      },
      "outputs": [],
      "source": [
        "# Instalar dependências (-q para instalação silenciosa)\n",
        "!pip install -q jedi>=0.16, llama-index llama-index-llms-openai llama-index-llms-groq llama-index-experimental gradio fpdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bbf94cd",
      "metadata": {
        "id": "8bbf94cd"
      },
      "source": [
        "##1.1 Para uso no Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "MnIk3zEA-Vaw"
      },
      "id": "MnIk3zEA-Vaw",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 Imports"
      ],
      "metadata": {
        "id": "TfVHgRx83GYA"
      },
      "id": "TfVHgRx83GYA"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "327f6a9c",
      "metadata": {
        "id": "327f6a9c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import textwrap\n",
        "import re\n",
        "from pydantic import BaseModel, Field, field_validator, ConfigDict, ValidationError\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.experimental.query_engine import PandasQueryEngine\n",
        "from llama_index.core.workflow import Workflow, Event, StartEvent as BaseStartEvent, StopEvent, step\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from google.colab import userdata\n",
        "from typing import Any, List, Tuple, Optional\n",
        "import asyncio\n",
        "import gradio as gr\n",
        "from fpdf import FPDF\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 Instruções e Prompts\n",
        "\n",
        "(Importante para validar a saída, pode ser usado como debug ou  )"
      ],
      "metadata": {
        "id": "3YY-0c2l-i5M"
      },
      "id": "3YY-0c2l-i5M"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== INSTRUÇÕES PARA CONVERSÃO DE CONSULTAS =====\n",
        "instruction_str = (\n",
        "    \"1. Converta a consulta para código Python executável usando Pandas.\\n\"\n",
        "    \"2. A linha final do código deve ser uma expressão Python que possa ser chamada com a função `eval()`.\\n\"\n",
        "    \"3. O código deve representar uma solução para a consulta.\\n\"\n",
        "    \"4. IMPRIMA APENAS A EXPRESSÃO FINAL.\\n\"\n",
        "    \"5. Não coloque a expressão entre aspas.\\n\"\n",
        "    \"6. Evite atribuições (=) na linha final - prefira expressões que retornem valores.\\n\"\n",
        "    \"7. Para operações de múltiplas linhas, termine com uma expressão que retorne o resultado.\\n\"\n",
        "    \"8. Exemplos válidos:\\n\"\n",
        "    \"   - df.groupby('coluna')['valor'].sum()\\n\"\n",
        "    \"   - df['coluna'].value_counts().head(5)\\n\"\n",
        "    \"   - df.describe()\\n\"\n",
        "    \"9. Evite códigos como 'df['coluna'] = valor' - prefira consultas que retornem dados.\\n\"\n",
        ")\n",
        "\n",
        "# ===== PROMPTS =====\n",
        "pandas_prompt_str = (\n",
        "    \"Você está trabalhando com um dataframe do pandas em Python chamado `df`.\\n\"\n",
        "    \"{colunas_detalhes}\\n\\n\"\n",
        "    \"Este é o resultado de `print(df.head())`:\\n\"\n",
        "    \"{df_str}\\n\\n\"\n",
        "    \"Siga estas instruções:\\n\"\n",
        "    \"{instruction_str}\\n\"\n",
        "    \"Consulta: {query_str}\\n\\n\"\n",
        "    \"Expressão:\"\n",
        ")\n",
        "\n",
        "RESPONSE_SYNTHESIS_PROMPT_STR = (\n",
        "   \"Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\\n\"\n",
        "   \"Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante.\\n\"\n",
        "   \"Consulta: {query_str}\\n\\n\"\n",
        "   \"Instruções do Pandas (opcional):\\n{pandas_instructions}\\n\\n\"\n",
        "   \"Saída do Pandas: {pandas_output}\\n\\n\"\n",
        "   \"Resposta: \"\n",
        "   \"Ao final, exibir o código usado para gerar a resposta, no formato: O código utilizado foi {pandas_instructions}\"\n",
        ")\n",
        "\n",
        "print(\"✅ Prompts configurados com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElcLXNqi-m2w",
        "outputId": "b5842144-9cae-4291-f03f-2c3730db40aa"
      },
      "id": "ElcLXNqi-m2w",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Prompts configurados com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 Configuração Pydantic V2"
      ],
      "metadata": {
        "id": "eaOg-rIf3jaL"
      },
      "id": "eaOg-rIf3jaL"
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMConfig(BaseModel):\n",
        "    model: str = Field(..., description=\"Nome do modelo Groq a ser usado\")\n",
        "    api_key: str = Field(..., description=\"Chave da API Groq\")\n",
        "    data_url: str = Field(..., description=\"URL do CSV com os dados\")\n",
        "\n",
        "    @field_validator(\"data_url\")\n",
        "    @classmethod\n",
        "    def validar_url(cls, v: str) -> str:\n",
        "        if not (v.startswith(\"http://\") or v.startswith(\"https://\")):\n",
        "            raise ValueError(\"data_url deve começar com http:// ou https://\")\n",
        "        return v\n",
        "\n",
        "    @field_validator(\"api_key\")\n",
        "    @classmethod\n",
        "    def validar_api_key(cls, v: str) -> str:\n",
        "        if not v or len(v.strip()) == 0:\n",
        "            raise ValueError(\"api_key não pode ser vazia\")\n",
        "        return v\n",
        "\n",
        "print(\"✅ Configuração LLM com Pydantic criada!\")\n",
        "\n",
        "\n",
        "# ===== HISTÓRICO DE PERGUNTAS/RESPOSTAS =====\n",
        "class Historico(BaseModel):\n",
        "    entradas: List[Tuple[str, str]] = []\n",
        "\n",
        "    def adicionar(self, pergunta: str, resposta: str):\n",
        "        \"\"\"Adiciona uma entrada ao histórico se pergunta e resposta forem válidas.\"\"\"\n",
        "        if pergunta and resposta:\n",
        "            self.entradas.append((pergunta, resposta))\n",
        "\n",
        "print(\"✅ Modelo de histórico com Pydantic criado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf65iXIp3riw",
        "outputId": "ae7e06e0-893e-49be-e7f6-a138e04f4f06"
      },
      "id": "zf65iXIp3riw",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuração LLM com Pydantic criada!\n",
            "✅ Modelo de histórico com Pydantic criado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5 Modelos de Eventos\n",
        "\n",
        "(Rastrear cada passo da interação, como um histórico organizado)"
      ],
      "metadata": {
        "id": "lHeWjLLu-tjv"
      },
      "id": "lHeWjLLu-tjv"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Modelos de Eventos com Pydantic ---\n",
        "\n",
        "class CodeEvent(Event):\n",
        "    pandas_prompt: str\n",
        "    query: str\n",
        "    df: pd.DataFrame\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "class OutputEvent(Event):\n",
        "    pandas_code: str\n",
        "    pandas_output: object = None\n",
        "    query: str\n",
        "    pandas_prompt: str\n",
        "    df: pd.DataFrame\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "class ExecutedEvent(Event):\n",
        "    pandas_code: str\n",
        "    pandas_output: object = None\n",
        "    query: str\n",
        "    pandas_prompt: str\n",
        "    df: pd.DataFrame\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "print(\"✅ Eventos com DataFrame propagado corrigidos!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJvzUYbg-zP0",
        "outputId": "fd05d0ed-a0e0-4a6d-a452-838a6d8f7dda"
      },
      "id": "MJvzUYbg-zP0",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Eventos com DataFrame propagado corrigidos!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6 Funções Auxiliares"
      ],
      "metadata": {
        "id": "zoVRLbkg38zx"
      },
      "id": "zoVRLbkg38zx"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2ecab43e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ecab43e",
        "outputId": "11b46a0f-d5d7-436a-e459-fd6d010d5a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Funções auxiliares configuradas!\n"
          ]
        }
      ],
      "source": [
        "def carregar_arquivo(caminho_arquivo: str, df_estado: pd.DataFrame = None):\n",
        "    \"\"\"\n",
        "    Carrega um CSV do caminho fornecido. Se caminho_arquivo for None, mantém df_estado.\n",
        "    Retorna mensagem de status e DataFrame atualizado.\n",
        "    \"\"\"\n",
        "    if caminho_arquivo is None or caminho_arquivo == \"\":\n",
        "        return \"Nenhum arquivo enviado. Usando dados atuais.\", df_estado\n",
        "    try:\n",
        "        df_novo = pd.read_csv(caminho_arquivo)\n",
        "        return \"Arquivo carregado com sucesso!\", df_novo\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao carregar arquivo: {str(e)}\", df_estado\n",
        "\n",
        "def formatar_texto(response: str, largura: int = 100, imprimir: bool = True):\n",
        "    texto_formatado = textwrap.fill(response, width=largura)\n",
        "    if imprimir:\n",
        "        print(texto_formatado)\n",
        "    return texto_formatado\n",
        "\n",
        "def descricao_colunas(df: pd.DataFrame) -> str:\n",
        "    descricao = \"\\n\".join([f\"`{col}`: {str(df[col].dtype)}\" for col in df.columns])\n",
        "    return \"Colunas do DataFrame:\\n\" + descricao\n",
        "\n",
        "def limpar_codigo_pandas(codigo: str) -> str:\n",
        "    \"\"\"Limpa e valida o código Pandas gerado pela LLM\"\"\"\n",
        "    codigo = re.sub(r'```(?:python)?\\n?', '', codigo)\n",
        "    linhas = codigo.split('\\n')\n",
        "    codigo_limpo = []\n",
        "\n",
        "    for linha in linhas:\n",
        "        linha = linha.strip()\n",
        "        if (linha and\n",
        "            not linha.startswith('#') and\n",
        "            not linha.startswith('//') and\n",
        "            not linha.lower().startswith('resposta:') and\n",
        "            not linha.lower().startswith('resultado:') and\n",
        "            not linha.lower().startswith('código:')):\n",
        "            codigo_limpo.append(linha)\n",
        "\n",
        "    codigo_final = '\\n'.join(codigo_limpo).strip()\n",
        "\n",
        "    # Se há múltiplas linhas, pega a última linha como expressão final\n",
        "    if '\\n' in codigo_final:\n",
        "        linhas_codigo = [l.strip() for l in codigo_final.split('\\n') if l.strip()]\n",
        "        # Pega a última linha que seja uma expressão (não atribuição)\n",
        "        for linha in reversed(linhas_codigo):\n",
        "            if not ('=' in linha and not linha.startswith('df[')):\n",
        "                codigo_final = linha\n",
        "                break\n",
        "\n",
        "    return codigo_final\n",
        "\n",
        "print(\"✅ Funções auxiliares configuradas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7 Configuração da API e Dados"
      ],
      "metadata": {
        "id": "ynQMHepO4AOC"
      },
      "id": "ynQMHepO4AOC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure sua chave da API Groq nos Secrets do Colab\n",
        "# Vá em:  (ícone da chave) -> Add new secret\n",
        "# Name: Groq_API\n",
        "# Value: sua_chave_aqui\n",
        "\n",
        "try:\n",
        "    key = userdata.get(\"Groq_API\")\n",
        "    print(\"✅ Chave API carregada com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Erro ao carregar chave API:\", e)\n",
        "    print(\"Configure a chave 'Groq_API' nos Secrets do Colab\")\n",
        "\n",
        "# ===== CONFIGURAÇÃO E DADOS =====\n",
        "config = LLMConfig(\n",
        "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "    api_key=key,\n",
        "    data_url=\"https://raw.githubusercontent.com/YuriArduino/Estudos_Artificial_Intelligence/refs/heads/Dados/vendas.csv\"\n",
        ")\n",
        "\n",
        "df = pd.read_csv(config.data_url)\n",
        "Settings.llm = Groq(model=config.model, api_key=config.api_key)\n",
        "\n",
        "print(\" Estrutura do DataFrame:\")\n",
        "print(df.head())\n",
        "print(f\"\\n Colunas disponíveis:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\n Info do DataFrame:\")\n",
        "print(df.info())\n",
        "print(f\"\\n✅ Configuração completa! Dataset: {df.shape[0]} linhas, {df.shape[1]} colunas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPIEtIXE4Inc",
        "outputId": "0ce164a5-7e2d-4e53-c5a8-db9bd3df6e42"
      },
      "id": "FPIEtIXE4Inc",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Chave API carregada com sucesso!\n",
            " Estrutura do DataFrame:\n",
            "     ID_compra filial       cidade tipo_cliente     genero       tipo_produto  \\\n",
            "0  750-67-8428      A  Santo André       Membro   Feminino     Saúde e Beleza   \n",
            "1  226-31-3081      C  São Caetano       Normal   Feminino        Eletrônicos   \n",
            "2  631-41-3108      A  Santo André       Normal  Masculino               Casa   \n",
            "3  123-19-1176      A  Santo André       Membro  Masculino     Saúde e Beleza   \n",
            "4  373-73-7910      A  Santo André       Normal  Masculino  Esportes e Viagem   \n",
            "\n",
            "   preco_unitario  quantidade  imposto_5%     total        data      hora  \\\n",
            "0           74.69           7     26.1415  548.9715  2024-01-05  13:08:00   \n",
            "1           15.28           5      3.8200   80.2200  2024-03-08  10:29:00   \n",
            "2           46.33           7     16.2155  340.5255  2024-03-03  13:23:00   \n",
            "3           58.22           8     23.2880  489.0480  2024-01-27  20:33:00   \n",
            "4           86.31           7     30.2085  634.3785  2024-02-08  10:37:00   \n",
            "\n",
            "     forma_pagamento  avaliacao  \n",
            "0   Carteira Digital        9.1  \n",
            "1           Dinheiro        9.6  \n",
            "2  Cartão de Crédito        7.4  \n",
            "3   Carteira Digital        8.4  \n",
            "4   Carteira Digital        5.3  \n",
            "\n",
            " Colunas disponíveis:\n",
            "['ID_compra', 'filial', 'cidade', 'tipo_cliente', 'genero', 'tipo_produto', 'preco_unitario', 'quantidade', 'imposto_5%', 'total', 'data', 'hora', 'forma_pagamento', 'avaliacao']\n",
            "\n",
            " Info do DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ID_compra        1000 non-null   object \n",
            " 1   filial           1000 non-null   object \n",
            " 2   cidade           1000 non-null   object \n",
            " 3   tipo_cliente     1000 non-null   object \n",
            " 4   genero           1000 non-null   object \n",
            " 5   tipo_produto     1000 non-null   object \n",
            " 6   preco_unitario   1000 non-null   float64\n",
            " 7   quantidade       1000 non-null   int64  \n",
            " 8   imposto_5%       1000 non-null   float64\n",
            " 9   total            1000 non-null   float64\n",
            " 10  data             1000 non-null   object \n",
            " 11  hora             1000 non-null   object \n",
            " 12  forma_pagamento  1000 non-null   object \n",
            " 13  avaliacao        1000 non-null   float64\n",
            "dtypes: float64(4), int64(1), object(9)\n",
            "memory usage: 109.5+ KB\n",
            "None\n",
            "\n",
            "✅ Configuração completa! Dataset: 1000 linhas, 14 colunas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8 Classe Workflow Principal"
      ],
      "metadata": {
        "id": "yYMx5O6c_EPc"
      },
      "id": "yYMx5O6c_EPc"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b825ff55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b825ff55",
        "outputId": "a966f8bf-fa97-4cee-97eb-54cfe97c9491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Workflow robusto definido!\n"
          ]
        }
      ],
      "source": [
        "# --- Workflow Compatível com Diferentes Versões ---\n",
        "from llama_index.core.workflow import Workflow, step, StartEvent, StopEvent\n",
        "import pandas as pd\n",
        "\n",
        "class PandasWorkflow(Workflow):\n",
        "\n",
        "    @step(pass_context=True)  # Adiciona pass_context para compatibilidade\n",
        "    async def iniciar_processamento(self, ctx, ev: StartEvent) -> CodeEvent:\n",
        "        \"\"\"\n",
        "        Step que GARANTE receber StartEvent\n",
        "        \"\"\"\n",
        "        print(f\" StartEvent recebido no workflow!\")\n",
        "        print(f\"📝 Tipo do evento: {type(ev)}\")\n",
        "        print(f\"📋 Conteúdo: {dir(ev)}\")\n",
        "\n",
        "        # Múltiplas formas de extrair dados para máxima compatibilidade\n",
        "        query = None\n",
        "        df_local = None\n",
        "\n",
        "        # Método 1: Atributos diretos\n",
        "        if hasattr(ev, 'query'):\n",
        "            query = ev.query\n",
        "            df_local = ev.df\n",
        "            print(\"✅ Dados extraídos via atributos diretos\")\n",
        "\n",
        "        # Método 2: get() se disponível\n",
        "        elif hasattr(ev, 'get'):\n",
        "            query = ev.get('query')\n",
        "            df_local = ev.get('df')\n",
        "            print(\"✅ Dados extraídos via get()\")\n",
        "\n",
        "        # Método 3: Dicionário\n",
        "        elif hasattr(ev, '__getitem__'):\n",
        "            try:\n",
        "                query = ev['query']\n",
        "                df_local = ev['df']\n",
        "                print(\"✅ Dados extraídos via índice\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Método 4: Contexto do workflow\n",
        "        if query is None and hasattr(ctx, 'data'):\n",
        "            query = ctx.data.get('query')\n",
        "            df_local = ctx.data.get('df')\n",
        "            print(\"✅ Dados extraídos via contexto\")\n",
        "\n",
        "        # Fallback: usar dados globais se nada funcionar\n",
        "        if query is None:\n",
        "            print(\"⚠️ Usando fallback para dados\")\n",
        "            query = getattr(self, '_temp_query', 'Consulta padrão')\n",
        "            df_local = getattr(self, '_temp_df', pd.DataFrame())\n",
        "\n",
        "        print(f\"📊 Query final: {query}\")\n",
        "        print(f\"📊 DataFrame shape: {df_local.shape if df_local is not None else 'None'}\")\n",
        "\n",
        "        # Processa o prompt\n",
        "        colunas_info = descricao_colunas(df_local)\n",
        "        prompt_text = pandas_prompt_str.format(\n",
        "            colunas_detalhes=colunas_info,\n",
        "            df_str=df_local.head(5),\n",
        "            instruction_str=instruction_str,\n",
        "            query_str=query\n",
        "        )\n",
        "\n",
        "        return CodeEvent(\n",
        "            pandas_prompt=prompt_text,\n",
        "            query=query,\n",
        "            df=df_local\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def gerar_codigo(self, ev: CodeEvent) -> OutputEvent:\n",
        "        \"\"\"Gera código pandas\"\"\"\n",
        "        print(f\"🔧 Gerando código para: {ev.query}\")\n",
        "\n",
        "        response = await Settings.llm.acomplete(ev.pandas_prompt)\n",
        "        codigo_bruto = str(response).strip()\n",
        "        codigo_limpo = limpar_codigo_pandas(codigo_bruto)\n",
        "        print(f\"✅ Código: {codigo_limpo}\")\n",
        "\n",
        "        return OutputEvent(\n",
        "            pandas_code=codigo_limpo,\n",
        "            pandas_output=None,\n",
        "            query=ev.query,\n",
        "            pandas_prompt=ev.pandas_prompt,\n",
        "            df=ev.df\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def executar_codigo(self, ev: OutputEvent) -> ExecutedEvent:\n",
        "        \"\"\"Executa o código\"\"\"\n",
        "        print(f\"▶️ Executando código: {ev.pandas_code}\")\n",
        "\n",
        "        try:\n",
        "            contexto = {\"df\": ev.df, \"pd\": pd, \"__builtins__\": __builtins__}\n",
        "            resultado = eval(ev.pandas_code, contexto)\n",
        "            print(f\"✅ Resultado: {resultado}\")\n",
        "        except Exception as e:\n",
        "            resultado = f\"Erro: {str(e)}\"\n",
        "            print(f\"❌ {resultado}\")\n",
        "\n",
        "        return ExecutedEvent(\n",
        "            pandas_code=ev.pandas_code,\n",
        "            pandas_output=resultado,\n",
        "            query=ev.query,\n",
        "            pandas_prompt=ev.pandas_prompt,\n",
        "            df=ev.df\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def finalizar(self, ev: ExecutedEvent) -> StopEvent:\n",
        "        \"\"\"Finaliza com resposta\"\"\"\n",
        "        print(f\" Finalizando processamento\")\n",
        "\n",
        "        if isinstance(ev.pandas_output, str) and \"Erro\" in ev.pandas_output:\n",
        "            resposta_final = f\"Não foi possível processar: {ev.pandas_output}\"\n",
        "        else:\n",
        "            prompt_text = RESPONSE_SYNTHESIS_PROMPT_STR.format(\n",
        "                query_str=ev.query,\n",
        "                pandas_instructions=ev.pandas_code,\n",
        "                pandas_output=ev.pandas_output\n",
        "            )\n",
        "            resposta = await Settings.llm.acomplete(prompt_text)\n",
        "            resposta_final = str(resposta).strip()\n",
        "\n",
        "        return StopEvent(result={\n",
        "            \"resposta_final\": resposta_final,\n",
        "            \"pandas_code\": ev.pandas_code,\n",
        "            \"pandas_output\": ev.pandas_output,\n",
        "            \"query\": ev.query\n",
        "        })\n",
        "\n",
        "print(\"✅ Workflow robusto definido!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9 Função de Execução"
      ],
      "metadata": {
        "id": "XUvrzCXQ_KWI"
      },
      "id": "XUvrzCXQ_KWI"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6e04d1ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e04d1ba",
        "outputId": "06e64573-7aab-4abe-94ab-18b44d46cf1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Funções robustas definidas!\n",
            "✅ Funções de execução adaptadas para DataFrame dinâmico!\n"
          ]
        }
      ],
      "source": [
        "async def executar_consulta(query: str, df_local: pd.DataFrame, mostrar_detalhes: bool = True):\n",
        "    \"\"\"\n",
        "    Versão robusta que funciona com diferentes configurações\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\" Iniciando processamento: {query}\")\n",
        "\n",
        "        # Tentativa 1: Workflow padrão\n",
        "        try:\n",
        "            wf = PandasWorkflow()\n",
        "\n",
        "            # Armazena dados temporariamente no workflow para fallback\n",
        "            wf._temp_query = query\n",
        "            wf._temp_df = df_local\n",
        "\n",
        "            # Tenta diferentes formas de criar StartEvent\n",
        "            try:\n",
        "                # Método 1: StartEvent com atributos\n",
        "                start_event = StartEvent()\n",
        "                start_event.query = query\n",
        "                start_event.df = df_local\n",
        "                result = await wf.run(start_event)\n",
        "            except:\n",
        "                # Método 2: run com parâmetros diretos\n",
        "                result = await wf.run(query=query, df=df_local)\n",
        "\n",
        "            print(f\"✅ Workflow executado com sucesso!\")\n",
        "\n",
        "            if hasattr(result, 'result'):\n",
        "                dados = result.result\n",
        "\n",
        "                if mostrar_detalhes:\n",
        "                    print(\"\\n === RESULTADO ===\")\n",
        "                    print(f\"Query: {dados.get('query')}\")\n",
        "                    print(f\"Código: {dados.get('pandas_code')}\")\n",
        "                    print(f\"Output: {dados.get('pandas_output')}\")\n",
        "                    print(f\"Resposta: {dados.get('resposta_final')}\")\n",
        "\n",
        "                return type('WorkflowResult', (), dados)()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Workflow falhou: {e}\")\n",
        "            raise\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Todas as tentativas falharam: {e}\")\n",
        "        print(\"🔄 Tentando processamento direto...\")\n",
        "\n",
        "        # Fallback: processamento direto sem workflow\n",
        "        return await processar_consulta_direta(query, df_local)\n",
        "\n",
        "# Função de processamento direto (fallback)\n",
        "async def processar_consulta_direta(query: str, df_local: pd.DataFrame):\n",
        "    \"\"\"Processamento sem workflow como fallback\"\"\"\n",
        "    try:\n",
        "        print(\" Processamento direto iniciado...\")\n",
        "\n",
        "        # Gerar código\n",
        "        colunas_info = descricao_colunas(df_local)\n",
        "        prompt_text = pandas_prompt_str.format(\n",
        "            colunas_detalhes=colunas_info,\n",
        "            df_str=df_local.head(5),\n",
        "            instruction_str=instruction_str,\n",
        "            query_str=query\n",
        "        )\n",
        "\n",
        "        response = await Settings.llm.acomplete(prompt_text)\n",
        "        codigo_limpo = limpar_codigo_pandas(str(response).strip())\n",
        "        print(f\"✅ Código: {codigo_limpo}\")\n",
        "\n",
        "        # Executar código\n",
        "        try:\n",
        "            contexto = {\"df\": df_local, \"pd\": pd, \"__builtins__\": __builtins__}\n",
        "            resultado = eval(codigo_limpo, contexto)\n",
        "            print(f\"✅ Resultado: {resultado}\")\n",
        "        except Exception as e:\n",
        "            resultado = f\"Erro na execução: {str(e)}\"\n",
        "\n",
        "        # Sintetizar resposta\n",
        "        if isinstance(resultado, str) and \"Erro\" in resultado:\n",
        "            resposta_final = f\"Não foi possível processar: {resultado}\"\n",
        "        else:\n",
        "            prompt_synthesis = RESPONSE_SYNTHESIS_PROMPT_STR.format(\n",
        "                query_str=query,\n",
        "                pandas_instructions=codigo_limpo,\n",
        "                pandas_output=resultado\n",
        "            )\n",
        "            resposta = await Settings.llm.acomplete(prompt_synthesis)\n",
        "            resposta_final = str(resposta).strip()\n",
        "\n",
        "        return type('DirectResult', (), {\n",
        "            'resposta_final': resposta_final,\n",
        "            'pandas_code': codigo_limpo,\n",
        "            'pandas_output': resultado,\n",
        "            'query': query\n",
        "        })()\n",
        "\n",
        "    except Exception as e:\n",
        "        return type('ErrorResult', (), {\n",
        "            'resposta_final': f\"❌ Erro no processamento: {str(e)}\",\n",
        "            'pandas_code': '',\n",
        "            'pandas_output': None,\n",
        "            'query': query\n",
        "        })()\n",
        "\n",
        "print(\"✅ Funções robustas definidas!\")\n",
        "\n",
        "async def executar_multiplas_consultas(consultas: list, df_local: pd.DataFrame = None):\n",
        "    \"\"\"\n",
        "    Executa várias consultas em sequência usando um DataFrame opcional.\n",
        "    \"\"\"\n",
        "    resultados = []\n",
        "\n",
        "    for i, consulta in enumerate(consultas, 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"CONSULTA {i}/{len(consultas)}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        resultado = await executar_consulta(consulta, df_local=df_local)\n",
        "        resultados.append(resultado)\n",
        "\n",
        "        print(\"\\n\")  # Espaçamento entre consultas\n",
        "\n",
        "    return resultados\n",
        "\n",
        "print(\"✅ Funções de execução adaptadas para DataFrame dinâmico!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.2 Funções auxiliares Gradio"
      ],
      "metadata": {
        "id": "-296ewDprziH"
      },
      "id": "-296ewDprziH"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Função para carregar CSV ---\n",
        "def carregar_dados(file, df_estado):\n",
        "    if file is None:\n",
        "        return \"❌ Nenhum arquivo selecionado\", df_estado\n",
        "    try:\n",
        "        df_local = pd.read_csv(file)\n",
        "        return f\"✅ Arquivo carregado com sucesso! {df_local.shape[0]} linhas, {df_local.shape[1]} colunas.\", df_local\n",
        "    except Exception as e:\n",
        "        return f\"❌ Erro ao carregar arquivo: {str(e)}\", df_estado\n",
        "\n",
        "\n",
        "# --- Função para executar consulta com workflow ---\n",
        "async def executar_consulta_async(pergunta, df_local):\n",
        "    \"\"\"\n",
        "    Função assíncrona simplificada para o Gradio\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resultado = await executar_consulta(pergunta, df_local, mostrar_detalhes=False)\n",
        "\n",
        "        if resultado is not None:\n",
        "            return resultado\n",
        "        else:\n",
        "            return type('MockResult', (), {\n",
        "                'resposta_final': \"❌ Erro: Workflow não executou corretamente\",\n",
        "                'pandas_code': '',\n",
        "                'pandas_output': None,\n",
        "                'query': pergunta\n",
        "            })()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro na função async: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return type('MockResult', (), {\n",
        "            'resposta_final': f\"❌ Erro: {str(e)}\",\n",
        "            'pandas_code': '',\n",
        "            'pandas_output': None,\n",
        "            'query': pergunta\n",
        "        })()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro no workflow: {str(e)}\")\n",
        "        # Retorna um objeto mock em caso de erro\n",
        "        return type('MockResult', (), {\n",
        "            'resposta_final': f\"❌ Erro ao processar consulta: {str(e)}\",\n",
        "            'pandas_code': '',\n",
        "            'pandas_output': None,\n",
        "            'query': pergunta\n",
        "        })()\n",
        "\n",
        "\n",
        "# --- Função para processar perguntas (versão síncrona para Gradio) ---\n",
        "def processar_pergunta(pergunta, df_local, historico: Historico):\n",
        "    if df_local is None:\n",
        "        return \"❌ Nenhum arquivo CSV carregado.\", historico\n",
        "\n",
        "    if not pergunta or not pergunta.strip():\n",
        "        return \"❌ Digite uma pergunta válida.\", historico\n",
        "\n",
        "    try:\n",
        "        # Executa a função assíncrona do workflow\n",
        "        resultado = asyncio.run(executar_consulta_async(pergunta, df_local))\n",
        "        resposta = resultado.resposta_final if hasattr(resultado, 'resposta_final') else \"❌ Erro ao processar a consulta.\"\n",
        "\n",
        "        # Atualiza o histórico usando Pydantic\n",
        "        historico.adicionar(pergunta, resposta)\n",
        "\n",
        "        return resposta, historico\n",
        "\n",
        "    except Exception as e:\n",
        "        erro_msg = f\"❌ Erro ao processar pergunta: {str(e)}\"\n",
        "        historico.adicionar(pergunta, erro_msg)\n",
        "        return erro_msg, historico\n",
        "\n",
        "\n",
        "# --- Função para gerar PDF ---\n",
        "def gerar_pdf(historico: Historico):\n",
        "    if not historico.entradas:\n",
        "        return \"❌ Nenhum dado para adicionar ao PDF\"\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        caminho_pdf = f\"relatorio_pandas_{timestamp}.pdf\"\n",
        "\n",
        "        pdf = FPDF()\n",
        "        pdf.add_page()\n",
        "        pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "        # Título do relatório\n",
        "        pdf.set_font(\"Arial\", \"B\", 16)\n",
        "        pdf.cell(0, 10, \"Relatório de Consultas Pandas\", ln=True, align=\"C\")\n",
        "        pdf.ln(10)\n",
        "\n",
        "        # Adiciona cada pergunta e resposta\n",
        "        for i, (pergunta, resposta) in enumerate(historico.entradas, 1):\n",
        "            # Pergunta\n",
        "            pdf.set_font(\"Arial\", \"B\", 12)\n",
        "            pdf.multi_cell(0, 8, f\"Pergunta {i}: {pergunta}\")\n",
        "            pdf.ln(2)\n",
        "\n",
        "            # Resposta\n",
        "            pdf.set_font(\"Arial\", \"\", 10)\n",
        "            pdf.multi_cell(0, 6, f\"Resposta: {resposta}\")\n",
        "            pdf.ln(8)\n",
        "\n",
        "        pdf.output(caminho_pdf)\n",
        "        return f\"✅ PDF gerado: {caminho_pdf}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Erro ao gerar PDF: {str(e)}\"\n",
        "\n",
        "\n",
        "print(\"✅ Funções auxiliares do Gradio corrigidas!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CC_I9Rlr_YF",
        "outputId": "6ab145fe-0573-4e28-ab56-0166a99618e5"
      },
      "id": "7CC_I9Rlr_YF",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Funções auxiliares do Gradio corrigidas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.1 Gradio"
      ],
      "metadata": {
        "id": "10D8zK05iSbj"
      },
      "id": "10D8zK05iSbj"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Interface Gradio Corrigida ---\n",
        "import gradio as gr\n",
        "\n",
        "# --- Interface Gradio ---\n",
        "with gr.Blocks(title=\"Pandas CSV Analyzer\", theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🐼 Consultas em CSV com Pandas via Workflow\n",
        "\n",
        "    Faça upload de um arquivo CSV e faça perguntas sobre os dados em linguagem natural!\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            # Upload CSV\n",
        "            input_arquivo = gr.File(\n",
        "                file_count=\"single\",\n",
        "                type=\"filepath\",\n",
        "                label=\"📁 Upload do arquivo CSV\",\n",
        "                file_types=[\".csv\"]\n",
        "            )\n",
        "            upload_status = gr.Textbox(\n",
        "                label=\"📊 Status do Upload\",\n",
        "                interactive=False,\n",
        "                placeholder=\"Nenhum arquivo carregado ainda...\"\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            # Informações do dataset\n",
        "            gr.Markdown(\"### ℹ️ Informações do Dataset\")\n",
        "            gr.Markdown(\"O status do upload aparecerá ao lado.\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            # Entrada de pergunta\n",
        "            input_pergunta = gr.Textbox(\n",
        "                label=\"❓ Digite sua pergunta sobre os dados\",\n",
        "                placeholder=\"Ex: Qual a média da coluna idade? Quantas linhas tem o dataset?\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            # Botões\n",
        "            botao_enviar = gr.Button(\"🚀 Enviar Pergunta\", variant=\"primary\", size=\"lg\")\n",
        "            botao_limpar = gr.Button(\"🗑️ Limpar\", variant=\"secondary\")\n",
        "\n",
        "    # Saída da resposta\n",
        "    output_resposta = gr.Textbox(\n",
        "        label=\"💬 Resposta\",\n",
        "        lines=5,\n",
        "        interactive=False,\n",
        "        placeholder=\"A resposta aparecerá aqui após enviar uma pergunta...\"\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            # Histórico e PDF\n",
        "            gr.Markdown(\"### 📋 Histórico e Relatórios\")\n",
        "            botao_pdf = gr.Button(\"📄 Gerar Relatório PDF\", variant=\"secondary\")\n",
        "            output_pdf = gr.Textbox(\n",
        "                label=\"📁 Arquivo PDF\",\n",
        "                interactive=False,\n",
        "                placeholder=\"Nenhum PDF gerado ainda...\"\n",
        "            )\n",
        "\n",
        "    # Estados (invisíveis)\n",
        "    df_estado = gr.State(value=None)\n",
        "    historico_estado = gr.State(value=Historico())\n",
        "\n",
        "    # --- Conexões dos Eventos ---\n",
        "\n",
        "    # Upload do arquivo\n",
        "    input_arquivo.change(\n",
        "        fn=carregar_dados,\n",
        "        inputs=[input_arquivo, df_estado],\n",
        "        outputs=[upload_status, df_estado]\n",
        "    )\n",
        "\n",
        "    # Envio da pergunta\n",
        "    botao_enviar.click(\n",
        "        fn=processar_pergunta,\n",
        "        inputs=[input_pergunta, df_estado, historico_estado],\n",
        "        outputs=[output_resposta, historico_estado]\n",
        "    )\n",
        "\n",
        "    # Limpar campo de pergunta\n",
        "    botao_limpar.click(\n",
        "        fn=lambda: \"\",\n",
        "        outputs=[input_pergunta]\n",
        "    )\n",
        "\n",
        "    # Gerar PDF\n",
        "    botao_pdf.click(\n",
        "        fn=gerar_pdf,\n",
        "        inputs=[historico_estado],\n",
        "        outputs=[output_pdf]\n",
        "    )\n",
        "\n",
        "    # Enter para enviar\n",
        "    input_pergunta.submit(\n",
        "        fn=processar_pergunta,\n",
        "        inputs=[input_pergunta, df_estado, historico_estado],\n",
        "        outputs=[output_resposta, historico_estado]\n",
        "    )\n",
        "\n",
        "print(\"✅ Interface Gradio configurada e pronta!\")\n",
        "\n",
        "# Lança a interface\n",
        "if __name__ == \"__main__\":\n",
        "    app.launch(\n",
        "        debug=True,\n",
        "        share=False,  # Mude para True se quiser compartilhar publicamente\n",
        "        server_name=\"0.0.0.0\",  # Para funcionar no Colab\n",
        "        server_port=7860\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "xBhCifgHiU9r",
        "outputId": "43b531b6-939d-42b7-80ee-2097239f5f7a"
      },
      "id": "xBhCifgHiU9r",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Interface Gradio configurada e pronta!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Iniciando processamento: Qual é a quantidade de registros no arquivo?\n",
            "⚠️ Workflow falhou: The following services are not available: ctx\n",
            "❌ Todas as tentativas falharam: The following services are not available: ctx\n",
            "🔄 Tentando processamento direto...\n",
            " Processamento direto iniciado...\n",
            "✅ Código: df.shape[0]\n",
            "✅ Resultado: 1000\n",
            " Iniciando processamento: Qual é a quantidade de registros no arquivo?\n",
            "⚠️ Workflow falhou: The following services are not available: ctx\n",
            "❌ Todas as tentativas falharam: The following services are not available: ctx\n",
            "🔄 Tentando processamento direto...\n",
            " Processamento direto iniciado...\n",
            "✅ Código: df.shape[0]\n",
            "✅ Resultado: 1000\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##10 Teste Rápido"
      ],
      "metadata": {
        "id": "SnrigB_l_QVm"
      },
      "id": "SnrigB_l_QVm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste rápido para verificar se tudo está funcionando\n",
        "query_teste = \"Qual é a avaliação média de cada filial?\"\n",
        "result = await executar_consulta(query_teste)\n",
        "\n",
        "if result:\n",
        "    print(\"\\n Sistema funcionando perfeitamente!\")\n",
        "else:\n",
        "    print(\"\\n Houve algum problema - verifique a configuração da API\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mGuURyz__TPK",
        "outputId": "c9f8b059-b55e-4eeb-fdb8-fad7c3f12092"
      },
      "id": "mGuURyz__TPK",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "executar_consulta() missing 1 required positional argument: 'df_local'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2456210698.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Teste rápido para verificar se tudo está funcionando\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquery_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Qual é a avaliação média de cada filial?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mexecutar_consulta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: executar_consulta() missing 1 required positional argument: 'df_local'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11 Exemplos de Uso Individual"
      ],
      "metadata": {
        "id": "w7XxG1eC_Wk5"
      },
      "id": "w7XxG1eC_Wk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f8a50d",
      "metadata": {
        "id": "69f8a50d"
      },
      "outputs": [],
      "source": [
        "# Execute uma consulta por vez para testar\n",
        "\n",
        "# Exemplo 1\n",
        "query = \"Quais são os 5 produtos mais vendidos?\"\n",
        "result = await executar_consulta(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 2\n",
        "query = \"Qual o total de vendas por região?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "cLYZHwUK_ZwW"
      },
      "id": "cLYZHwUK_ZwW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 3\n",
        "query = \"Qual produto tem a maior margem de lucro?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "2rGJQRL__g-k"
      },
      "id": "2rGJQRL__g-k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 4\n",
        "query = \"Quantas vendas foram feitas em cada mês?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "7GmSKrxt_ia9"
      },
      "id": "7GmSKrxt_ia9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Qual o genêro que mais consome e o segmento do produto?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "QeXUbCZaOY2l"
      },
      "id": "QeXUbCZaOY2l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##12 Bateria de Testes"
      ],
      "metadata": {
        "id": "7gieDaX2_e2n"
      },
      "id": "7gieDaX2_e2n"
    },
    {
      "cell_type": "code",
      "source": [
        "# Executar múltiplas consultas de uma vez\n",
        "consultas_exemplo = [\n",
        "    \"Qual é a avaliação média de cada filial?\",\n",
        "    \"Quais são os 5 produtos mais vendidos?\",\n",
        "    \"Qual o total de vendas por região?\",\n",
        "    \"Qual produto tem a maior margem de lucro?\",\n",
        "    \"Quantas vendas foram feitas em cada mês?\",\n",
        "    \"Qual é a receita total por categoria de produto?\",\n",
        "    \"Qual filial teve melhor desempenho?\",\n",
        "    \"Mostre a distribuição de preços dos produtos\"\n",
        "]\n",
        "\n",
        "print(\" Executando bateria de testes...\")\n",
        "resultados = await executar_multiplas_consultas(consultas_exemplo)\n",
        "\n",
        "print(f\"\\n✅ Concluído! {len([r for r in resultados if r])} consultas processadas com sucesso.\")"
      ],
      "metadata": {
        "id": "7t268z2a_rK5"
      },
      "id": "7t268z2a_rK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##13 Modo Interativo"
      ],
      "metadata": {
        "id": "YU3bIuXj_ty_"
      },
      "id": "YU3bIuXj_ty_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Modo interativo - digite suas próprias consultas\n",
        "print(\" MODO INTERATIVO\")\n",
        "print(\"Digite suas consultas (digite 'sair' para terminar)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        query = input(\"\\n Sua consulta: \").strip()\n",
        "\n",
        "        if query.lower() in ['sair', 'exit', 'quit', '']:\n",
        "            print(\" Até logo!\")\n",
        "            break\n",
        "\n",
        "        await executar_consulta(query, mostrar_detalhes=False)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n Interrompido pelo usuário!\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\" Erro: {e}\")"
      ],
      "metadata": {
        "id": "DXM0Gh67_oiY"
      },
      "id": "DXM0Gh67_oiY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##14 Análise Manual dos Dados\n"
      ],
      "metadata": {
        "id": "YvXLkuzD_yrz"
      },
      "id": "YvXLkuzD_yrz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise dos dados originais para comparação\n",
        "print(\" ANÁLISE MANUAL DOS DADOS (para comparação)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"Estatísticas básicas:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(f\"\\nContagem por categoria:\")\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df[col].value_counts().head())\n",
        "\n",
        "print(f\"\\nValores nulos:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "ohovTGoP_7tG"
      },
      "id": "ohovTGoP_7tG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dicas e Informações"
      ],
      "metadata": {
        "id": "ETccYDWS_4Zc"
      },
      "id": "ETccYDWS_4Zc"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"💡 DICAS PARA USO:\")\n",
        "print(\"=\"*50)\n",
        "print(\"1. Para consultas complexas, seja específico\")\n",
        "print(\"2. Use nomes exatos das colunas mostradas na análise\")\n",
        "print(\"3. Experimente diferentes tipos de análise:\")\n",
        "print(\"   - Agrupamentos: 'média por categoria'\")\n",
        "print(\"   - Rankings: 'top 10 produtos'\")\n",
        "print(\"   - Filtros: 'vendas acima de X valor'\")\n",
        "print(\"   - Séries temporais: 'vendas por mês'\")\n",
        "print(\"4. O sistema mostra o código Pandas usado!\")\n",
        "\n",
        "print(f\"\\n INFORMAÇÕES DO DATASET:\")\n",
        "print(f\"Suas colunas: {list(df.columns)}\")\n",
        "print(f\"Quantidade de dados: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
        "print(f\"Tipos de dados: {df.dtypes.value_counts().to_dict()}\")\n",
        "\n",
        "print(f\"\\n SUGESTÕES DE CONSULTAS:\")\n",
        "example_queries = [\n",
        "    \"Qual a correlação entre preço e quantidade vendida?\",\n",
        "    \"Mostre a distribuição de vendas por dia da semana\",\n",
        "    \"Qual filial tem o melhor desempenho?\",\n",
        "    \"Compare as vendas do primeiro e último trimestre\",\n",
        "    \"Identifique produtos com baixo estoque\",\n",
        "    \"Qual é o produto mais caro por categoria?\",\n",
        "    \"Mostre as vendas médias por vendedor\",\n",
        "    \"Qual região tem menor variação de preços?\"\n",
        "]\n",
        "\n",
        "for i, query in enumerate(example_queries, 1):\n",
        "    print(f\"{i}. {query}\")\n",
        "\n",
        "print(f\"\\n MODELO UTILIZADO: {config.model}\")\n",
        "print(f\" URL DOS DADOS: {config.data_url}\")"
      ],
      "metadata": {
        "id": "lEPP6tuj_925"
      },
      "id": "lEPP6tuj_925",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notas de Uso:\n",
        "\n",
        "*   Configuração da API: Configure sua chave Groq nos Secrets do Colab\n",
        "*   Execução sequencial: Execute as células na ordem\n",
        "*   Personalização: Modifique a URL dos dados na Célula 6\n",
        "*   Debug: Os logs mostram o código Pandas gerado\n",
        "*   Interativo: Use a Célula 12 para consultas livres\n",
        "\n",
        "##Estrutura final:\n",
        "\n",
        "*   Instalação automática de dependências\n",
        "* Configuração completa da API\n",
        "* Exploração automática dos dados\n",
        "* Sistema de workflow robusto\n",
        "* Exemplos prontos para uso\n",
        "* Modo interativo\n",
        "* Sistema de debug integrado\n",
        "\n",
        "\n",
        ">Desenvolvido por Yuri Arduino Bernardineli Alves | GitHub: [YuriArduino](https://github.com/YuriArduino) | E-mail: yuriarduino@gmail.com"
      ],
      "metadata": {
        "id": "_TbE6Un3AGjs"
      },
      "id": "_TbE6Un3AGjs"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}