{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuriArduino/Estudos_Artificial_Intelligence/blob/main/pandas_workflow_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Workflow com LlamaIndex Workflows\n",
        "\n",
        ">Este notebook demonstra como criar um sistema de análise de dados usando LlamaIndex, Pandas e Groq para consultas em linguagem natural.\n",
        "\n",
        "\n",
        "## Sobre a Atualização do LlamaIndex\n",
        "\n",
        "O **LlamaIndex** descontinuou o módulo **QueryPipeline** em favor de uma nova abordagem chamada **Workflows**.\n",
        "Essa mudança foi implementada na versão `0.11` do LlamaIndex, com o objetivo de oferecer uma arquitetura mais\n",
        "flexível e escalável para a construção de aplicações de IA generativa.\n",
        "\n",
        "### Por que o QueryPipeline foi descontinuado?\n",
        "O QueryPipeline era uma API declarativa útil para orquestrar consultas simples a avançadas sobre os dados.\n",
        "Porém, ele se mostrou limitado para cenários mais dinâmicos. Por isso, os **Workflows** foram introduzidos,\n",
        "trazendo uma arquitetura orientada a eventos para fluxos de trabalho mais sofisticados.\n",
        "\n",
        "### O que são Workflows?\n",
        "Workflows permitem orquestrar etapas personalizadas de forma assíncrona e condicional, facilitando\n",
        "integrações complexas e manipulação de dados em tempo real.\n",
        "\n",
        "**Documentação oficial:** [docs.llamaindex.ai](https://docs.llamaindex.ai)\n",
        "\n"
      ],
      "metadata": {
        "id": "3pzznnjN3W-Z"
      },
      "id": "3pzznnjN3W-Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Código:\n"
      ],
      "metadata": {
        "id": "KYxQbJBGAjb7"
      },
      "id": "KYxQbJBGAjb7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 Instalar Dependências:"
      ],
      "metadata": {
        "id": "ne3hDRwyAlhT"
      },
      "id": "ne3hDRwyAlhT"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eaa06244",
      "metadata": {
        "id": "eaa06244"
      },
      "outputs": [],
      "source": [
        "# Instalar dependências (-q para instalação silenciosa)\n",
        "!pip install -q jedi>=0.16 llama-index llama-index-llms-openai llama-index-llms-groq llama-index-experimental gradio fpdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bbf94cd",
      "metadata": {
        "id": "8bbf94cd"
      },
      "source": [
        "##1.1 Para uso no Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "MnIk3zEA-Vaw"
      },
      "id": "MnIk3zEA-Vaw",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 Imports"
      ],
      "metadata": {
        "id": "TfVHgRx83GYA"
      },
      "id": "TfVHgRx83GYA"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "327f6a9c",
      "metadata": {
        "id": "327f6a9c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import textwrap\n",
        "import re\n",
        "from pydantic import BaseModel, Field, field_validator, ConfigDict, ValidationError\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.core.workflow import Workflow, Event, StartEvent as BaseStartEvent, StopEvent, step\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from google.colab import userdata\n",
        "from typing import Any, List, Tuple, Optional\n",
        "import asyncio\n",
        "import gradio as gr\n",
        "from fpdf import FPDF\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 Instruções e Prompts\n",
        "\n",
        "(Importante para validar a saída, pode ser usado como debug ou  )"
      ],
      "metadata": {
        "id": "3YY-0c2l-i5M"
      },
      "id": "3YY-0c2l-i5M"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== INSTRUÇÕES PARA CONVERSÃO DE CONSULTAS =====\n",
        "instruction_str = (\n",
        "    \"1. Converta a consulta para código Python executável usando Pandas.\\n\"\n",
        "    \"2. A linha final do código deve ser uma expressão Python que possa ser chamada com a função `eval()`.\\n\"\n",
        "    \"3. O código deve representar uma solução para a consulta.\\n\"\n",
        "    \"4. IMPRIMA APENAS A EXPRESSÃO FINAL.\\n\"\n",
        "    \"5. Não coloque a expressão entre aspas.\\n\"\n",
        "    \"6. Evite atribuições (=) na linha final - prefira expressões que retornem valores.\\n\"\n",
        "    \"7. Para operações de múltiplas linhas, termine com uma expressão que retorne o resultado.\\n\"\n",
        "    \"8. Exemplos válidos:\\n\"\n",
        "    \"   - df.groupby('coluna')['valor'].sum()\\n\"\n",
        "    \"   - df['coluna'].value_counts().head(5)\\n\"\n",
        "    \"   - df.describe()\\n\"\n",
        "    \"9. Evite códigos como 'df['coluna'] = valor' - prefira consultas que retornem dados.\\n\"\n",
        ")\n",
        "\n",
        "# ===== PROMPTS =====\n",
        "pandas_prompt_str = (\n",
        "    \"Você está trabalhando com um dataframe do pandas em Python chamado `df`.\\n\"\n",
        "    \"{colunas_detalhes}\\n\\n\"\n",
        "    \"Este é o resultado de `print(df.head())`:\\n\"\n",
        "    \"{df_str}\\n\\n\"\n",
        "    \"Siga estas instruções:\\n\"\n",
        "    \"{instruction_str}\\n\"\n",
        "    \"Consulta: {query_str}\\n\\n\"\n",
        "    \"Expressão:\"\n",
        ")\n",
        "\n",
        "RESPONSE_SYNTHESIS_PROMPT_STR = (\n",
        "   \"Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\\n\"\n",
        "   \"Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante.\\n\"\n",
        "   \"Consulta: {query_str}\\n\\n\"\n",
        "   \"Instruções do Pandas (opcional):\\n{pandas_instructions}\\n\\n\"\n",
        "   \"Saída do Pandas: {pandas_output}\\n\\n\"\n",
        "   \"Resposta: \"\n",
        "   \"Ao final, exibir o código usado para gerar a resposta, no formato: O código utilizado foi {pandas_instructions}\"\n",
        ")\n",
        "\n",
        "print(\"✅ Prompts configurados com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElcLXNqi-m2w",
        "outputId": "cb116b60-d8d7-4640-b120-0559a32c619b"
      },
      "id": "ElcLXNqi-m2w",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Prompts configurados com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 Configuração Pydantic V2"
      ],
      "metadata": {
        "id": "eaOg-rIf3jaL"
      },
      "id": "eaOg-rIf3jaL"
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMConfig(BaseModel):\n",
        "    model: str = Field(..., description=\"Nome do modelo Groq a ser usado\")\n",
        "    api_key: str = Field(..., description=\"Chave da API Groq\")\n",
        "    data_url: str = Field(..., description=\"URL do CSV com os dados\")\n",
        "\n",
        "    @field_validator(\"data_url\")\n",
        "    @classmethod\n",
        "    def validar_url(cls, v: str) -> str:\n",
        "        if not (v.startswith(\"http://\") or v.startswith(\"https://\")):\n",
        "            raise ValueError(\"data_url deve começar com http:// ou https://\")\n",
        "        return v\n",
        "\n",
        "    @field_validator(\"api_key\")\n",
        "    @classmethod\n",
        "    def validar_api_key(cls, v: str) -> str:\n",
        "        if not v or len(v.strip()) == 0:\n",
        "            raise ValueError(\"api_key não pode ser vazia\")\n",
        "        return v\n",
        "\n",
        "print(\"✅ Configuração LLM com Pydantic criada!\")\n",
        "\n",
        "class Historico(BaseModel):\n",
        "    entradas: List[Tuple[str, str]] = []\n",
        "\n",
        "    def adicionar(self, pergunta: str, resposta: str):\n",
        "        \"\"\"Adiciona uma entrada ao histórico se pergunta e resposta forem válidas.\"\"\"\n",
        "        if pergunta and resposta:\n",
        "            self.entradas.append((pergunta, resposta))\n",
        "\n",
        "print(\"✅ Modelo de histórico com Pydantic criado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf65iXIp3riw",
        "outputId": "89a31ccf-ad59-4d88-dc61-235ec7332675"
      },
      "id": "zf65iXIp3riw",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuração LLM com Pydantic criada!\n",
            "✅ Modelo de histórico com Pydantic criado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5 Modelos de Eventos\n",
        "\n",
        "(Rastrear cada passo da interação, como um histórico organizado)"
      ],
      "metadata": {
        "id": "lHeWjLLu-tjv"
      },
      "id": "lHeWjLLu-tjv"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Modelos de Eventos com Pydantic ---\n",
        "\n",
        "# --- Evento de início customizado para garantir os dados de entrada ---\n",
        "class StartEvent(BaseStartEvent):\n",
        "    query: str\n",
        "    df: pd.DataFrame\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "# --- Eventos intermediários para propagar os dados no workflow ---\n",
        "class CodeEvent(Event):\n",
        "    pandas_prompt: str\n",
        "    query: str\n",
        "    df: pd.DataFrame\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "class OutputEvent(Event):\n",
        "    pandas_code: str\n",
        "    query: str\n",
        "    df: pd.DataFrame\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "class ExecutedEvent(Event):\n",
        "    pandas_code: str\n",
        "    pandas_output: Any\n",
        "    query: str\n",
        "    df: pd.DataFrame\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "\n",
        "print(\"✅ Modelos de eventos do workflow definidos com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJvzUYbg-zP0",
        "outputId": "a85c6265-17f9-4f92-ddf1-629321dda658"
      },
      "id": "MJvzUYbg-zP0",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelos de eventos do workflow definidos com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6 Funções Auxiliares"
      ],
      "metadata": {
        "id": "zoVRLbkg38zx"
      },
      "id": "zoVRLbkg38zx"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2ecab43e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ecab43e",
        "outputId": "8266ec25-6414-44a6-917b-b15389cd37cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Funções auxiliares configuradas!\n"
          ]
        }
      ],
      "source": [
        "def carregar_arquivo(caminho_arquivo: str, df_estado: Optional[pd.DataFrame] = None) -> Tuple[str, Optional[pd.DataFrame]]:\n",
        "    \"\"\"\n",
        "    Carrega um CSV do caminho fornecido. Se caminho_arquivo for None, mantém df_estado.\n",
        "    Retorna mensagem de status e DataFrame atualizado.\n",
        "    \"\"\"\n",
        "    if not caminho_arquivo:\n",
        "        return \"Nenhum arquivo enviado. Usando dados atuais (se houver).\", df_estado\n",
        "    try:\n",
        "        df_novo = pd.read_csv(caminho_arquivo)\n",
        "        return \"Arquivo carregado com sucesso!\", df_novo\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao carregar arquivo: {str(e)}\", df_estado\n",
        "\n",
        "def formatar_texto(response: str, largura: int = 100, imprimir: bool = True):\n",
        "    texto_formatado = textwrap.fill(response, width=largura)\n",
        "    if imprimir:\n",
        "        print(texto_formatado)\n",
        "    return texto_formatado\n",
        "\n",
        "def descricao_colunas(df: pd.DataFrame) -> str:\n",
        "    descricao = \"\\n\".join([f\"`{col}`: {str(df[col].dtype)}\" for col in df.columns])\n",
        "    return \"Colunas do DataFrame:\\n\" + descricao\n",
        "\n",
        "def limpar_codigo_pandas(codigo: str) -> str:\n",
        "    \"\"\"Limpa e valida o código Pandas gerado pela LLM.\"\"\"\n",
        "    codigo = re.sub(r'```(?:python)?\\n?', '', codigo) # Remove ```python\n",
        "    codigo = re.sub(r'```', '', codigo) # Remove ``` de fechamento\n",
        "    linhas = [linha.strip() for linha in codigo.split('\\n') if linha.strip()]\n",
        "\n",
        "    # Filtra linhas que são comentários ou texto explicativo\n",
        "    codigo_filtrado = [\n",
        "        linha for linha in linhas if not (\n",
        "            linha.startswith('#') or\n",
        "            'resposta:' in linha.lower() or\n",
        "            'resultado:' in linha.lower()\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    if not codigo_filtrado:\n",
        "        return \"\"\n",
        "\n",
        "    # Se houver várias linhas, a última é geralmente a expressão de retorno\n",
        "    return codigo_filtrado[-1]\n",
        "\n",
        "print(\"✅ Funções auxiliares configuradas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7 Configuração da API e Dados"
      ],
      "metadata": {
        "id": "ynQMHepO4AOC"
      },
      "id": "ynQMHepO4AOC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure sua chave da API Groq nos Secrets do Colab\n",
        "# Vá em:  (ícone da chave) -> Add new secret\n",
        "# Name: Groq_API\n",
        "# Value: sua_chave_aqui\n",
        "\n",
        "try:\n",
        "    key = userdata.get(\"Groq_API\")\n",
        "    print(\"✅ Chave API carregada com sucesso!\")\n",
        "except Exception as e:\n",
        "    key = None\n",
        "    print(f\"❌ Erro ao carregar chave API: {e}. Por favor, configure a chave 'Groq_API' nos Secrets do Colab.\")\n",
        "\n",
        "# ===== CONFIGURAÇÃO E DADOS =====\n",
        "if key:\n",
        "    config = LLMConfig(\n",
        "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        api_key=key,\n",
        "        data_url=\"https://raw.githubusercontent.com/YuriArduino/Estudos_Artificial_Intelligence/refs/heads/Dados/vendas.csv\"\n",
        "    )\n",
        "\n",
        "    df = pd.read_csv(config.data_url)\n",
        "    Settings.llm = Groq(model=config.model, api_key=config.api_key)\n",
        "\n",
        "    print(\"\\n Estrutura do DataFrame:\")\n",
        "    print(df.head())\n",
        "    print(f\"\\n✅ Configuração completa! Dataset: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
        "else:\n",
        "    df = None\n",
        "    print(\"\\n⚠️ A execução será interrompida pois a API Key não foi carregada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPIEtIXE4Inc",
        "outputId": "54ff12a2-bf1a-4c87-b380-a864ad373447"
      },
      "id": "FPIEtIXE4Inc",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Chave API carregada com sucesso!\n",
            "\n",
            " Estrutura do DataFrame:\n",
            "     ID_compra filial       cidade tipo_cliente     genero       tipo_produto  \\\n",
            "0  750-67-8428      A  Santo André       Membro   Feminino     Saúde e Beleza   \n",
            "1  226-31-3081      C  São Caetano       Normal   Feminino        Eletrônicos   \n",
            "2  631-41-3108      A  Santo André       Normal  Masculino               Casa   \n",
            "3  123-19-1176      A  Santo André       Membro  Masculino     Saúde e Beleza   \n",
            "4  373-73-7910      A  Santo André       Normal  Masculino  Esportes e Viagem   \n",
            "\n",
            "   preco_unitario  quantidade  imposto_5%     total        data      hora  \\\n",
            "0           74.69           7     26.1415  548.9715  2024-01-05  13:08:00   \n",
            "1           15.28           5      3.8200   80.2200  2024-03-08  10:29:00   \n",
            "2           46.33           7     16.2155  340.5255  2024-03-03  13:23:00   \n",
            "3           58.22           8     23.2880  489.0480  2024-01-27  20:33:00   \n",
            "4           86.31           7     30.2085  634.3785  2024-02-08  10:37:00   \n",
            "\n",
            "     forma_pagamento  avaliacao  \n",
            "0   Carteira Digital        9.1  \n",
            "1           Dinheiro        9.6  \n",
            "2  Cartão de Crédito        7.4  \n",
            "3   Carteira Digital        8.4  \n",
            "4   Carteira Digital        5.3  \n",
            "\n",
            "✅ Configuração completa! Dataset: 1000 linhas, 14 colunas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8 Classe Workflow Principal"
      ],
      "metadata": {
        "id": "yYMx5O6c_EPc"
      },
      "id": "yYMx5O6c_EPc"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b825ff55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b825ff55",
        "outputId": "26416063-7f4a-40c6-9534-4b8db621cd54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Workflow robusto e simplificado definido!\n"
          ]
        }
      ],
      "source": [
        "class PandasWorkflow(Workflow):\n",
        "\n",
        "    @step\n",
        "    async def iniciar_processamento(self, ev: StartEvent) -> CodeEvent:\n",
        "        \"\"\"\n",
        "        Prepara o prompt para gerar o código Pandas.\n",
        "        Os dados 'query' e 'df' são recebidos diretamente do StartEvent.\n",
        "        \"\"\"\n",
        "        print(\"  [Workflow] Etapa 1: Iniciando processamento...\")\n",
        "        colunas_info = descricao_colunas(ev.df)\n",
        "        prompt_text = pandas_prompt_str.format(\n",
        "            colunas_detalhes=colunas_info,\n",
        "            df_str=ev.df.head(5).to_string(),\n",
        "            instruction_str=instruction_str,\n",
        "            query_str=ev.query\n",
        "        )\n",
        "        return CodeEvent(pandas_prompt=prompt_text, query=ev.query, df=ev.df)\n",
        "\n",
        "    @step\n",
        "    async def gerar_codigo(self, ev: CodeEvent) -> OutputEvent:\n",
        "        \"\"\"Gera código pandas a partir do prompt.\"\"\"\n",
        "        print(\"  [Workflow] Etapa 2: Gerando código Pandas...\")\n",
        "        response = await Settings.llm.acomplete(ev.pandas_prompt)\n",
        "        codigo_limpo = limpar_codigo_pandas(str(response).strip())\n",
        "        print(f\"   ✅ Código gerado: {codigo_limpo}\")\n",
        "        return OutputEvent(pandas_code=codigo_limpo, query=ev.query, df=ev.df)\n",
        "\n",
        "    @step\n",
        "    async def executar_codigo(self, ev: OutputEvent) -> ExecutedEvent:\n",
        "        \"\"\"Executa o código Pandas gerado.\"\"\"\n",
        "        print(\" [Workflow] Etapa 3: Executando código...\")\n",
        "        try:\n",
        "            # Contexto seguro para a execução do eval\n",
        "            contexto = {\"df\": ev.df, \"pd\": pd}\n",
        "            resultado = eval(ev.pandas_code, {\"__builtins__\": {}}, contexto)\n",
        "            print(f\"   ✅ Resultado da execução: {resultado}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Erro na execução: {e}\")\n",
        "            resultado = f\"Erro ao executar o código: {str(e)}\"\n",
        "        return ExecutedEvent(\n",
        "            pandas_code=ev.pandas_code,\n",
        "            pandas_output=resultado,\n",
        "            query=ev.query,\n",
        "            df=ev.df\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def finalizar_e_sintetizar(self, ev: ExecutedEvent) -> StopEvent:\n",
        "        \"\"\"Gera a resposta final em linguagem natural.\"\"\"\n",
        "        print(\"  [Workflow] Etapa 4: Sintetizando resposta final...\")\n",
        "        if isinstance(ev.pandas_output, str) and \"Erro\" in ev.pandas_output:\n",
        "            resposta_final = f\"Não foi possível processar a consulta devido a um erro. {ev.pandas_output}\"\n",
        "        else:\n",
        "            prompt_synthesis = RESPONSE_SYNTHESIS_PROMPT_STR.format(\n",
        "                query_str=ev.query,\n",
        "                pandas_instructions=ev.pandas_code,\n",
        "                pandas_output=str(ev.pandas_output)\n",
        "            )\n",
        "            response = await Settings.llm.acomplete(prompt_synthesis)\n",
        "            resposta_final = str(response).strip()\n",
        "\n",
        "        print(\" [Workflow] Finalizado com sucesso!\")\n",
        "        return StopEvent(result={\n",
        "            \"resposta_final\": resposta_final,\n",
        "            \"pandas_code\": ev.pandas_code,\n",
        "        })\n",
        "\n",
        "print(\"✅ Workflow robusto e simplificado definido!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9 Função de Execução"
      ],
      "metadata": {
        "id": "XUvrzCXQ_KWI"
      },
      "id": "XUvrzCXQ_KWI"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6e04d1ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e04d1ba",
        "outputId": "d4074f0d-a47e-44bc-91de-3c77443e59c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Função de execução do workflow corrigida: sem fallback e com tratamento de erro explícito!\n"
          ]
        }
      ],
      "source": [
        "async def executar_consulta(query: str, df_local: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Executa o workflow de ponta a ponta e trata os erros de forma explícita, sem fallback.\n",
        "    \"\"\"\n",
        "    if df_local is None:\n",
        "        return {\n",
        "            \"resposta_final\": \"Erro: O DataFrame não foi carregado.\",\n",
        "            \"pandas_code\": \"N/A\"\n",
        "        }\n",
        "    if not query or not query.strip():\n",
        "        return {\n",
        "            \"resposta_final\": \"Erro: A consulta não pode ser vazia.\",\n",
        "            \"pandas_code\": \"N/A\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        print(f\"\\n Iniciando workflow para a consulta: '{query}'\")\n",
        "        wf = PandasWorkflow()\n",
        "\n",
        "        # O método run() está retornando o dicionário diretamente.\n",
        "        # A correção é tratar o resultado como o dicionário final.\n",
        "        resultado_final = await wf.run(query=query, df=df_local)\n",
        "\n",
        "        # Verificamos se o resultado é de fato um dicionário, como esperado.\n",
        "        if not isinstance(resultado_final, dict):\n",
        "             raise TypeError(f\"O workflow retornou um tipo inesperado: {type(resultado_final)}\")\n",
        "\n",
        "        return resultado_final\n",
        "\n",
        "    except Exception as e:\n",
        "        # SEM FALLBACK: Se o workflow falhar, reportamos o erro diretamente.\n",
        "        print(f\"❌ Erro crítico durante a execução do workflow: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Imprime o stack trace completo para depuração\n",
        "        return {\n",
        "            \"resposta_final\": f\"Ocorreu um erro crítico no workflow. Verifique os logs para detalhes. Erro: {str(e)}\",\n",
        "            \"pandas_code\": \"N/A - Falha no workflow\"\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"✅ Função de execução do workflow corrigida: sem fallback e com tratamento de erro explícito!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9.2 Funções auxiliares Gradio"
      ],
      "metadata": {
        "id": "-296ewDprziH"
      },
      "id": "-296ewDprziH"
    },
    {
      "cell_type": "code",
      "source": [
        "def carregar_dados(file, df_estado):\n",
        "    if file is None:\n",
        "        return \"❌ Nenhum arquivo selecionado\", df_estado\n",
        "    try:\n",
        "        df_local = pd.read_csv(file.name) # Corrigido para .name\n",
        "        return f\"✅ Arquivo carregado! {df_local.shape[0]} linhas, {df_local.shape[1]} colunas.\", df_local\n",
        "    except Exception as e:\n",
        "        return f\"❌ Erro ao carregar arquivo: {str(e)}\", df_estado\n",
        "\n",
        "def processar_pergunta(pergunta: str, df_local: Optional[pd.DataFrame], historico: Historico):\n",
        "    if df_local is None:\n",
        "        resposta = \"❌ Por favor, carregue um arquivo CSV primeiro.\"\n",
        "        return resposta, historico\n",
        "\n",
        "    if not pergunta or not pergunta.strip():\n",
        "        resposta = \"❌ Por favor, digite uma pergunta válida.\"\n",
        "        return resposta, historico\n",
        "\n",
        "    try:\n",
        "        # Executa a função assíncrona principal\n",
        "        resultado = asyncio.run(executar_consulta(pergunta, df_local))\n",
        "        resposta = resultado.get(\"resposta_final\", \"❌ Erro: a resposta não foi gerada.\")\n",
        "        historico.adicionar(pergunta, resposta)\n",
        "        return resposta, historico\n",
        "    except Exception as e:\n",
        "        erro_msg = f\"❌ Ocorreu um erro inesperado: {str(e)}\"\n",
        "        historico.adicionar(pergunta, erro_msg)\n",
        "        return erro_msg, historico\n",
        "\n",
        "def gerar_pdf(historico: Historico):\n",
        "    if not historico.entradas:\n",
        "        return \"❌ Nenhum histórico para gerar o PDF.\"\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        caminho_pdf = f\"relatorio_consultas_{timestamp}.pdf\"\n",
        "\n",
        "        pdf = FPDF()\n",
        "        pdf.add_page()\n",
        "        pdf.set_font(\"Arial\", size=10) # Usar UTF-8 para caracteres especiais\n",
        "        pdf.add_font('Arial', '', 'Arial.ttf', uni=True)\n",
        "\n",
        "\n",
        "        # Título\n",
        "        pdf.set_font(\"Arial\", \"B\", 16)\n",
        "        pdf.cell(0, 10, \"Relatório de Consultas ao CSV\", ln=True, align=\"C\")\n",
        "        pdf.ln(10)\n",
        "\n",
        "        for i, (pergunta, resposta) in enumerate(historico.entradas, 1):\n",
        "            # Pergunta\n",
        "            pdf.set_font(\"Arial\", \"B\", 12)\n",
        "            pdf.multi_cell(0, 8, f\"Pergunta {i}: {pergunta}\".encode('latin-1', 'replace').decode('latin-1'))\n",
        "            pdf.ln(2)\n",
        "\n",
        "            # Resposta\n",
        "            pdf.set_font(\"Arial\", \"\", 10)\n",
        "            pdf.multi_cell(0, 6, f\"Resposta: {resposta}\".encode('latin-1', 'replace').decode('latin-1'))\n",
        "            pdf.ln(8)\n",
        "\n",
        "        pdf.output(caminho_pdf)\n",
        "        return f\"✅ PDF gerado com sucesso: {caminho_pdf}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Erro ao gerar PDF: {str(e)}\"\n",
        "\n",
        "print(\"✅ Funções auxiliares do Gradio prontas!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CC_I9Rlr_YF",
        "outputId": "c3c4f71c-4e83-4b7a-e656-8aa42091ef0d"
      },
      "id": "7CC_I9Rlr_YF",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Funções auxiliares do Gradio prontas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9.1 Gradio"
      ],
      "metadata": {
        "id": "10D8zK05iSbj"
      },
      "id": "10D8zK05iSbj"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks(title=\"Pandas CSV Analyzer\", theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"# 🐼 Analisador de CSV com Pandas e LlamaIndex\")\n",
        "    gr.Markdown(\"Faça upload de um arquivo CSV e faça perguntas em linguagem natural!\")\n",
        "\n",
        "    # Estados (invisíveis) para armazenar o DataFrame e o histórico\n",
        "    df_estado = gr.State()\n",
        "    historico_estado = gr.State(value=Historico())\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            input_arquivo = gr.File(label=\"📁 Faça upload do seu arquivo CSV\", file_types=[\".csv\"])\n",
        "            upload_status = gr.Textbox(label=\"📊 Status do Upload\", interactive=False)\n",
        "            botao_pdf = gr.Button(\"📄 Gerar Relatório PDF\", variant=\"secondary\")\n",
        "            output_pdf = gr.Textbox(label=\"📁 Status do PDF\", interactive=False)\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot = gr.Chatbot(label=\"Histórico da Conversa\", height=500)\n",
        "            input_pergunta = gr.Textbox(label=\"❓ Digite sua pergunta\", placeholder=\"Ex: Qual o total de vendas por filial?\")\n",
        "            botao_enviar = gr.Button(\" Enviar\", variant=\"primary\")\n",
        "\n",
        "    def chat_interface(pergunta, chat_history, df_local, historico_obj):\n",
        "        if df_local is None:\n",
        "            chat_history.append((pergunta, \"❌ Por favor, carregue um arquivo CSV primeiro.\"))\n",
        "            return \"\", chat_history, historico_obj\n",
        "\n",
        "        # Chama a função de processamento principal\n",
        "        resposta, historico_obj_atualizado = processar_pergunta(pergunta, df_local, historico_obj)\n",
        "        chat_history.append((pergunta, resposta))\n",
        "        return \"\", chat_history, historico_obj_atualizado\n",
        "\n",
        "    # --- Conexões dos Eventos ---\n",
        "    input_arquivo.upload(\n",
        "        fn=carregar_dados,\n",
        "        inputs=[input_arquivo, df_estado],\n",
        "        outputs=[upload_status, df_estado]\n",
        "    )\n",
        "\n",
        "    botao_enviar.click(\n",
        "        fn=chat_interface,\n",
        "        inputs=[input_pergunta, chatbot, df_estado, historico_estado],\n",
        "        outputs=[input_pergunta, chatbot, historico_estado]\n",
        "    )\n",
        "\n",
        "    input_pergunta.submit(\n",
        "        fn=chat_interface,\n",
        "        inputs=[input_pergunta, chatbot, df_estado, historico_estado],\n",
        "        outputs=[input_pergunta, chatbot, historico_estado]\n",
        "    )\n",
        "\n",
        "    botao_pdf.click(\n",
        "        fn=gerar_pdf,\n",
        "        inputs=[historico_estado],\n",
        "        outputs=[output_pdf]\n",
        "    )\n",
        "\n",
        "print(\"✅ Interface Gradio configurada!\")\n",
        "\n",
        "# Lança a interface\n",
        "if __name__ == \"__main__\" and df is not None:\n",
        "    app.launch(debug=True, share=False)\n",
        "elif df is None:\n",
        "    print(\"❌ A interface Gradio não será iniciada pois a configuração da API falhou.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xBhCifgHiU9r",
        "outputId": "5fce2ec2-e777-407e-cde6-3d645e60331d"
      },
      "id": "xBhCifgHiU9r",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2411074614.py:19: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Histórico da Conversa\", height=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Interface Gradio configurada!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Iniciando workflow para a consulta: 'Qual é a quantidade de registros no arquivo?'\n",
            "➡️  [Workflow] Etapa 1: Iniciando processamento...\n",
            "➡️  [Workflow] Etapa 2: Gerando código Pandas...\n",
            "   ✅ Código gerado: df.shape[0]\n",
            "➡️  [Workflow] Etapa 3: Executando código...\n",
            "   ✅ Resultado da execução: 1000\n",
            "➡️  [Workflow] Etapa 4: Sintetizando resposta final...\n",
            "🏁 [Workflow] Finalizado com sucesso!\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mblock_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3157\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3158\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3159\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2411074614.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Lança a interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔴 A interface Gradio não será iniciada pois a configuração da API falhou.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[0m\n\u001b[1;32m   3053\u001b[0m             )\n\u001b[1;32m   3054\u001b[0m         ):\n\u001b[0;32m-> 3055\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3057\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTupleNoPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mblock_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3160\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Keyboard interruption in main thread... closing server.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3163\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtunnel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCURRENT_TUNNELS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3164\u001b[0m                 \u001b[0mtunnel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##10 Teste Rápido"
      ],
      "metadata": {
        "id": "SnrigB_l_QVm"
      },
      "id": "SnrigB_l_QVm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste rápido para verificar se a função principal está funcionando\n",
        "async def teste_rapido():\n",
        "    if df is not None:\n",
        "        query_teste = \"Qual é a avaliação média de cada filial?\"\n",
        "        # Corrigido: passando o df_local como argumento\n",
        "        resultado = await executar_consulta(query_teste, df_local=df)\n",
        "\n",
        "        if resultado and \"Erro\" not in resultado.get(\"resposta_final\", \"\"):\n",
        "            print(\"\\n✅ Sistema funcionando perfeitamente!\")\n",
        "            print(f\"Resposta: {resultado['resposta_final']}\")\n",
        "        else:\n",
        "            print(f\"\\n❌ Houve um problema no teste: {resultado}\")\n",
        "    else:\n",
        "        print(\"⚠️ Teste não executado: DataFrame não foi carregado.\")\n",
        "\n",
        "# Executar o teste\n",
        "await teste_rapido()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGuURyz__TPK",
        "outputId": "f58d0066-b608-4620-f366-7096a072e793"
      },
      "id": "mGuURyz__TPK",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Iniciando workflow para a consulta: 'Qual é a avaliação média de cada filial?'\n",
            "  [Workflow] Etapa 1: Iniciando processamento...\n",
            "  [Workflow] Etapa 2: Gerando código Pandas...\n",
            "   ✅ Código gerado: df.groupby('filial')['avaliacao'].mean()\n",
            " [Workflow] Etapa 3: Executando código...\n",
            "   ✅ Resultado da execução: filial\n",
            "A    7.027059\n",
            "B    6.818072\n",
            "C    7.072866\n",
            "Name: avaliacao, dtype: float64\n",
            "  [Workflow] Etapa 4: Sintetizando resposta final...\n",
            " [Workflow] Finalizado com sucesso!\n",
            "\n",
            "✅ Sistema funcionando perfeitamente!\n",
            "Resposta: A avaliação média de cada filial é a seguinte: \n",
            "\n",
            "- Filial A: 7,027059\n",
            "- Filial B: 6,818072\n",
            "- Filial C: 7,072866\n",
            "\n",
            "Esses valores indicam que a Filial C tem a melhor avaliação média, seguida de perto pela Filial A. A Filial B tem a avaliação média mais baixa entre as três.\n",
            "\n",
            "O código utilizado foi df.groupby('filial')['avaliacao'].mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11 Exemplos de Uso Individual"
      ],
      "metadata": {
        "id": "w7XxG1eC_Wk5"
      },
      "id": "w7XxG1eC_Wk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f8a50d",
      "metadata": {
        "id": "69f8a50d"
      },
      "outputs": [],
      "source": [
        "# Execute uma consulta por vez para testar\n",
        "\n",
        "# Exemplo 1\n",
        "query = \"Quais são os 5 produtos mais vendidos?\"\n",
        "result = await executar_consulta(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 2\n",
        "query = \"Qual o total de vendas por região?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "cLYZHwUK_ZwW"
      },
      "id": "cLYZHwUK_ZwW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 3\n",
        "query = \"Qual produto tem a maior margem de lucro?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "2rGJQRL__g-k"
      },
      "id": "2rGJQRL__g-k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 4\n",
        "query = \"Quantas vendas foram feitas em cada mês?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "7GmSKrxt_ia9"
      },
      "id": "7GmSKrxt_ia9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Qual o genêro que mais consome e o segmento do produto?\"\n",
        "result = await executar_consulta(query)"
      ],
      "metadata": {
        "id": "QeXUbCZaOY2l"
      },
      "id": "QeXUbCZaOY2l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##12 Bateria de Testes"
      ],
      "metadata": {
        "id": "7gieDaX2_e2n"
      },
      "id": "7gieDaX2_e2n"
    },
    {
      "cell_type": "code",
      "source": [
        "# Executar múltiplas consultas de uma vez\n",
        "consultas_exemplo = [\n",
        "    \"Qual é a avaliação média de cada filial?\",\n",
        "    \"Quais são os 5 produtos mais vendidos?\",\n",
        "    \"Qual o total de vendas por região?\",\n",
        "    \"Qual produto tem a maior margem de lucro?\",\n",
        "    \"Quantas vendas foram feitas em cada mês?\",\n",
        "    \"Qual é a receita total por categoria de produto?\",\n",
        "    \"Qual filial teve melhor desempenho?\",\n",
        "    \"Mostre a distribuição de preços dos produtos\"\n",
        "]\n",
        "\n",
        "print(\" Executando bateria de testes...\")\n",
        "resultados = await executar_multiplas_consultas(consultas_exemplo)\n",
        "\n",
        "print(f\"\\n✅ Concluído! {len([r for r in resultados if r])} consultas processadas com sucesso.\")"
      ],
      "metadata": {
        "id": "7t268z2a_rK5"
      },
      "id": "7t268z2a_rK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##13 Modo Interativo"
      ],
      "metadata": {
        "id": "YU3bIuXj_ty_"
      },
      "id": "YU3bIuXj_ty_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Modo interativo - digite suas próprias consultas\n",
        "print(\" MODO INTERATIVO\")\n",
        "print(\"Digite suas consultas (digite 'sair' para terminar)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        query = input(\"\\n Sua consulta: \").strip()\n",
        "\n",
        "        if query.lower() in ['sair', 'exit', 'quit', '']:\n",
        "            print(\" Até logo!\")\n",
        "            break\n",
        "\n",
        "        await executar_consulta(query, mostrar_detalhes=False)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n Interrompido pelo usuário!\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\" Erro: {e}\")"
      ],
      "metadata": {
        "id": "DXM0Gh67_oiY"
      },
      "id": "DXM0Gh67_oiY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##14 Análise Manual dos Dados\n"
      ],
      "metadata": {
        "id": "YvXLkuzD_yrz"
      },
      "id": "YvXLkuzD_yrz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise dos dados originais para comparação\n",
        "print(\" ANÁLISE MANUAL DOS DADOS (para comparação)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"Estatísticas básicas:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(f\"\\nContagem por categoria:\")\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df[col].value_counts().head())\n",
        "\n",
        "print(f\"\\nValores nulos:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "ohovTGoP_7tG"
      },
      "id": "ohovTGoP_7tG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dicas e Informações"
      ],
      "metadata": {
        "id": "ETccYDWS_4Zc"
      },
      "id": "ETccYDWS_4Zc"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"💡 DICAS PARA USO:\")\n",
        "print(\"=\"*50)\n",
        "print(\"1. Para consultas complexas, seja específico\")\n",
        "print(\"2. Use nomes exatos das colunas mostradas na análise\")\n",
        "print(\"3. Experimente diferentes tipos de análise:\")\n",
        "print(\"   - Agrupamentos: 'média por categoria'\")\n",
        "print(\"   - Rankings: 'top 10 produtos'\")\n",
        "print(\"   - Filtros: 'vendas acima de X valor'\")\n",
        "print(\"   - Séries temporais: 'vendas por mês'\")\n",
        "print(\"4. O sistema mostra o código Pandas usado!\")\n",
        "\n",
        "print(f\"\\n INFORMAÇÕES DO DATASET:\")\n",
        "print(f\"Suas colunas: {list(df.columns)}\")\n",
        "print(f\"Quantidade de dados: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
        "print(f\"Tipos de dados: {df.dtypes.value_counts().to_dict()}\")\n",
        "\n",
        "print(f\"\\n SUGESTÕES DE CONSULTAS:\")\n",
        "example_queries = [\n",
        "    \"Qual a correlação entre preço e quantidade vendida?\",\n",
        "    \"Mostre a distribuição de vendas por dia da semana\",\n",
        "    \"Qual filial tem o melhor desempenho?\",\n",
        "    \"Compare as vendas do primeiro e último trimestre\",\n",
        "    \"Identifique produtos com baixo estoque\",\n",
        "    \"Qual é o produto mais caro por categoria?\",\n",
        "    \"Mostre as vendas médias por vendedor\",\n",
        "    \"Qual região tem menor variação de preços?\"\n",
        "]\n",
        "\n",
        "for i, query in enumerate(example_queries, 1):\n",
        "    print(f\"{i}. {query}\")\n",
        "\n",
        "print(f\"\\n MODELO UTILIZADO: {config.model}\")\n",
        "print(f\" URL DOS DADOS: {config.data_url}\")"
      ],
      "metadata": {
        "id": "lEPP6tuj_925"
      },
      "id": "lEPP6tuj_925",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notas de Uso:\n",
        "\n",
        "*   Configuração da API: Configure sua chave Groq nos Secrets do Colab\n",
        "*   Execução sequencial: Execute as células na ordem\n",
        "*   Personalização: Modifique a URL dos dados na Célula 6\n",
        "*   Debug: Os logs mostram o código Pandas gerado\n",
        "*   Interativo: Use a Célula 12 para consultas livres\n",
        "\n",
        "##Estrutura final:\n",
        "\n",
        "*   Instalação automática de dependências\n",
        "* Configuração completa da API\n",
        "* Exploração automática dos dados\n",
        "* Sistema de workflow robusto\n",
        "* Exemplos prontos para uso\n",
        "* Modo interativo\n",
        "* Sistema de debug integrado\n",
        "\n",
        "\n",
        ">Desenvolvido por Yuri Arduino Bernardineli Alves | GitHub: [YuriArduino](https://github.com/YuriArduino) | E-mail: yuriarduino@gmail.com"
      ],
      "metadata": {
        "id": "_TbE6Un3AGjs"
      },
      "id": "_TbE6Un3AGjs"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}