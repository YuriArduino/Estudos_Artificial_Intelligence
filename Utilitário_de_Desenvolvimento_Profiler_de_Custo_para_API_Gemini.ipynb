{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8rgOebhPSAQr+fSOoe1Fm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuriArduino/Estudos_Artificial_Intelligence/blob/Imers%C3%A3o-Agentes-de-IA---Alura/Utilit%C3%A1rio_de_Desenvolvimento_Profiler_de_Custo_para_API_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMySFhHgGdo-",
        "outputId": "236bbb63-9fbc-4189-9382-44a336c733bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "import sys\n",
        "import textwrap\n",
        "import time"
      ],
      "metadata": {
        "id": "ftkhQE3XGgqj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0, # Maior mais criativo, Menor mais objetivo\n",
        "    )"
      ],
      "metadata": {
        "id": "jW5_up63GjwX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5xrdvSIGV5F",
        "outputId": "7c88b904-7d03-4a4f-9e58-e2bb74213376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ApiUsageMonitor ativo!\n"
          ]
        }
      ],
      "source": [
        "# C√©lula 1: O Novo Monitor de Uso da API (ApiUsageMonitor)\n",
        "\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class ApiUsageMonitor:\n",
        "    \"\"\"\n",
        "    Monitora o uso da API em tempo real, verificando os limites de taxa (RPM, TPM, RPD)\n",
        "    e emitindo alertas proativos. Baseado nos limites do Free Tier do gemini-1.5-flash.\n",
        "    \"\"\"\n",
        "    # --- Par√¢metros Extra√≠dos do Seu Relat√≥rio ---\n",
        "    RPM_LIMIT = 10\n",
        "    TPM_LIMIT = 250000\n",
        "    RPD_LIMIT = 250\n",
        "    WARN_THRESHOLD = 0.80  # Avisar quando atingir 80% do limite\n",
        "\n",
        "    def __init__(self):\n",
        "        # Usamos 'deque' para manter um log de requisi√ß√µes com tamanho limitado e eficiente\n",
        "        # Armazenamos tuplas de (timestamp, tokens_usados)\n",
        "        self.request_log = deque()\n",
        "        self.total_tokens_geral = 0\n",
        "        print(\"‚úÖ ApiUsageMonitor ativo!\")\n",
        "\n",
        "    def registrar_uso(self, usage_metadata):\n",
        "        \"\"\"Registra uma nova requisi√ß√£o no log.\"\"\"\n",
        "        if not usage_metadata:\n",
        "            return 0\n",
        "\n",
        "        tokens_usados = usage_metadata.get('total_tokens', 0)\n",
        "        timestamp_atual = time.time()\n",
        "\n",
        "        self.request_log.append((timestamp_atual, tokens_usados))\n",
        "        self.total_tokens_geral += tokens_usados\n",
        "\n",
        "        return tokens_usados\n",
        "\n",
        "    def check_and_warn_limits(self):\n",
        "        \"\"\"Verifica os logs e emite avisos se estiver perto dos limites.\"\"\"\n",
        "        now = time.time()\n",
        "        one_minute_ago = now - 60\n",
        "        one_day_ago = now - 86400\n",
        "\n",
        "        # Filtra os logs para as janelas de tempo relevantes\n",
        "        requests_last_minute = [r for r in self.request_log if r[0] > one_minute_ago]\n",
        "        requests_last_day = [r for r in self.request_log if r[0] > one_day_ago]\n",
        "\n",
        "        # Calcula o uso atual\n",
        "        current_rpm = len(requests_last_minute)\n",
        "        current_tpm = sum(tokens for _, tokens in requests_last_minute)\n",
        "        current_rpd = len(requests_last_day)\n",
        "\n",
        "        print(\"\\n--- ü©∫ Verifica√ß√£o de Limites ---\")\n",
        "        print(f\"RPM: {current_rpm}/{self.RPM_LIMIT} | TPM: {current_tpm}/{self.TPM_LIMIT} | RPD: {current_rpd}/{self.RPD_LIMIT}\")\n",
        "\n",
        "        # Emite os alertas\n",
        "        if current_rpm >= self.RPM_LIMIT * self.WARN_THRESHOLD:\n",
        "            print(f\"‚ö†Ô∏è ALERTA: Voc√™ atingiu {current_rpm / self.RPM_LIMIT:.0%} do seu limite de Requisi√ß√µes por Minuto (RPM).\")\n",
        "\n",
        "        if current_tpm >= self.TPM_LIMIT * self.WARN_THRESHOLD:\n",
        "            print(f\"‚ö†Ô∏è ALERTA: Voc√™ atingiu {current_tpm / self.TPM_LIMIT:.0%} do seu limite de Tokens por Minuto (TPM).\")\n",
        "\n",
        "        if current_rpd >= self.RPD_LIMIT * self.WARN_THRESHOLD:\n",
        "            print(f\"‚ö†Ô∏è ALERTA: Voc√™ atingiu {current_rpd / self.RPD_LIMIT:.0%} do seu limite de Requisi√ß√µes por Dia (RPD).\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "\n",
        "    def status(self):\n",
        "        \"\"\"Mostra o status geral.\"\"\"\n",
        "        print(f\"\\n--- üìä Status Geral ---\")\n",
        "        print(f\"Total de tokens na sess√£o: {self.total_tokens_geral}\")\n",
        "        print(f\"Total de requisi√ß√µes na sess√£o: {len(self.request_log)}\")\n",
        "        print(\"------------------------\")\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reseta o monitor.\"\"\"\n",
        "        self.request_log.clear()\n",
        "        self.total_tokens_geral = 0\n",
        "        print(\"üîÑ ApiUsageMonitor resetado!\")\n",
        "\n",
        "# Crie a inst√¢ncia do monitor uma vez\n",
        "monitor = ApiUsageMonitor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 2: Instanciando Nossos Monitores\n",
        "\n",
        "# O monitor principal que acumula tudo na sess√£o de trabalho.\n",
        "geral_monitor = ApiUsageMonitor()\n",
        "\n",
        "# Podemos declarar o monitor de tarefa aqui ou cri√°-lo quando precisarmos.\n",
        "# Por enquanto, vamos apenas declarar para ficar claro.\n",
        "timer_monitor = None\n",
        "\n",
        "print(\"\\n‚úÖ Monitores 'geral_monitor' e 'timer_monitor' prontos para uso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do5Xwtj8ITt8",
        "outputId": "aa59bf6b-bd18-4618-a2dd-494d941bc398"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ApiUsageMonitor ativo!\n",
            "\n",
            "‚úÖ Monitores 'geral_monitor' e 'timer_monitor' prontos para uso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 3: Fun√ß√µes Auxiliares Refatoradas\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def query(monitor_principal, monitor_tarefa=None):\n",
        "    \"\"\"\n",
        "    Processa uma query e registra o uso no monitor principal e,\n",
        "    opcionalmente, em um monitor de tarefa.\n",
        "    \"\"\"\n",
        "    query_text = input(\"Digite seu texto: \")\n",
        "    if not query_text.strip():\n",
        "        print(\"Nenhum texto inserido.\")\n",
        "        return\n",
        "\n",
        "    resposta = llm.invoke(query_text)\n",
        "\n",
        "    # Registra o uso no monitor principal SEMPRE\n",
        "    tokens_desta_msg = monitor_principal.registrar_uso(resposta.usage_metadata)\n",
        "\n",
        "    # Se um monitor de tarefa foi fornecido, registra nele tamb√©m\n",
        "    if monitor_tarefa:\n",
        "        monitor_tarefa.registrar_uso(resposta.usage_metadata)\n",
        "\n",
        "    # (O c√≥digo de formata√ß√£o e exibi√ß√£o continua o mesmo)\n",
        "    prefixo = \" Resposta: \"\n",
        "    largura_maxima = 90\n",
        "    texto_formatado = textwrap.fill(resposta.content, width=largura_maxima, initial_indent=prefixo, subsequent_indent=' ' * len(prefixo))\n",
        "    print(f\"\\n{texto_formatado}\")\n",
        "\n",
        "    # Exibe o status da chamada e a verifica√ß√£o de limites do monitor principal\n",
        "    print(f\"\\n {tokens_desta_msg} tokens (Total na sess√£o: {monitor_principal.total_tokens_geral})\")\n",
        "    monitor_principal.check_and_warn_limits()\n",
        "\n",
        "def status(monitor_instancia):\n",
        "    \"\"\"Mostra o status de uma inst√¢ncia de monitor espec√≠fica.\"\"\"\n",
        "    if not isinstance(monitor_instancia, ApiUsageMonitor):\n",
        "        print(\"ERRO: Forne√ßa uma inst√¢ncia v√°lida do ApiUsageMonitor.\")\n",
        "        return\n",
        "    monitor_instancia.status()\n",
        "\n",
        "def reset(monitor_instancia):\n",
        "    \"\"\"Reseta uma inst√¢ncia de monitor espec√≠fica.\"\"\"\n",
        "    if not isinstance(monitor_instancia, ApiUsageMonitor):\n",
        "        print(\"ERRO: Forne√ßa uma inst√¢ncia v√°lida do ApiUsageMonitor.\")\n",
        "        return\n",
        "    monitor_instancia.reset()"
      ],
      "metadata": {
        "id": "pWvm--P1GaH6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- C√©lula de Testes de Confiabilidade ---\n",
        "\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "# Recriamos a classe aqui para que a c√©lula seja autossuficiente\n",
        "class ApiUsageMonitor:\n",
        "    RPM_LIMIT = 10\n",
        "    TPM_LIMIT = 250000\n",
        "    RPD_LIMIT = 250\n",
        "    WARN_THRESHOLD = 0.80\n",
        "\n",
        "    def __init__(self):\n",
        "        self.request_log = deque()\n",
        "        self.total_tokens_geral = 0\n",
        "\n",
        "    def registrar_uso(self, usage_metadata):\n",
        "        if not usage_metadata: return 0\n",
        "        tokens_usados = usage_metadata.get('total_tokens', 0)\n",
        "        self.request_log.append((time.time(), tokens_usados))\n",
        "        self.total_tokens_geral += tokens_usados\n",
        "        return tokens_usados\n",
        "\n",
        "    def check_and_warn_limits(self):\n",
        "        now = time.time()\n",
        "        one_minute_ago = now - 60\n",
        "        one_day_ago = now - 86400\n",
        "        requests_last_minute = [r for r in self.request_log if r[0] > one_minute_ago]\n",
        "        requests_last_day = [r for r in self.request_log if r[0] > one_day_ago]\n",
        "        current_rpm = len(requests_last_minute)\n",
        "        current_tpm = sum(tokens for _, tokens in requests_last_minute)\n",
        "        current_rpd = len(requests_last_day)\n",
        "\n",
        "        print(\"\\n--- ü©∫ Verifica√ß√£o de Limites ---\")\n",
        "        print(f\"RPM: {current_rpm}/{self.RPM_LIMIT} | TPM: {current_tpm}/{self.TPM_LIMIT} | RPD: {current_rpd}/{self.RPD_LIMIT}\")\n",
        "\n",
        "        if current_rpm >= self.RPM_LIMIT * self.WARN_THRESHOLD:\n",
        "            print(f\"‚úÖ SUCESSO NO TESTE: Alerta de RPM emitido como esperado.\")\n",
        "        if current_tpm >= self.TPM_LIMIT * self.WARN_THRESHOLD:\n",
        "            print(f\"‚úÖ SUCESSO NO TESTE: Alerta de TPM emitido como esperado.\")\n",
        "        if current_rpd >= self.RPD_LIMIT * self.WARN_THRESHOLD:\n",
        "            print(f\"‚úÖ SUCESSO NO TESTE: Alerta de RPD emitido como esperado.\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "    def status(self):\n",
        "        print(f\"\\n--- üìä Status ---\")\n",
        "        print(f\"Total de tokens: {self.total_tokens_geral}\")\n",
        "        print(f\"Total de requisi√ß√µes: {len(self.request_log)}\")\n",
        "        print(\"------------------\")\n",
        "\n",
        "    def reset(self):\n",
        "        self.request_log.clear()\n",
        "        self.total_tokens_geral = 0\n",
        "\n",
        "\n",
        "# --- IN√çCIO DOS TESTES AUTOMATIZADOS ---\n",
        "print(\"üöÄ Iniciando testes de confiabilidade para ApiUsageMonitor...\\n\")\n",
        "\n",
        "# --- Teste 1: Simula√ß√£o de Alerta de RPM (Requisi√ß√µes por Minuto) ---\n",
        "print(\"=\"*50)\n",
        "print(\"### Teste 1: Simula√ß√£o de Alerta de RPM ###\")\n",
        "test_monitor_rpm = ApiUsageMonitor()\n",
        "now = time.time()\n",
        "# Simulamos 9 requisi√ß√µes nos √∫ltimos 60 segundos (acima do limite de 80% de 10)\n",
        "# e 1 requisi√ß√£o antiga que deve ser ignorada.\n",
        "fake_log_rpm = [\n",
        "    (now - 70, 100), # Requisi√ß√£o antiga\n",
        "    (now - 50, 100), (now - 45, 100), (now - 40, 100),\n",
        "    (now - 35, 100), (now - 30, 100), (now - 25, 100),\n",
        "    (now - 20, 100), (now - 15, 100), (now - 10, 100) # 9 requisi√ß√µes recentes\n",
        "]\n",
        "test_monitor_rpm.request_log.extend(fake_log_rpm)\n",
        "test_monitor_rpm.check_and_warn_limits()\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "# --- Teste 2: Simula√ß√£o de Alerta de TPM (Tokens por Minuto) ---\n",
        "print(\"\\n### Teste 2: Simula√ß√£o de Alerta de TPM ###\")\n",
        "test_monitor_tpm = ApiUsageMonitor()\n",
        "now = time.time()\n",
        "# O limite de alerta √© 200.000 (80% de 250.000). Simulamos 3 requisi√ß√µes\n",
        "# que somam 210.000 tokens nos √∫ltimos 60 segundos.\n",
        "fake_log_tpm = [\n",
        "    (now - 80, 100000), # Requisi√ß√£o antiga com muitos tokens\n",
        "    (now - 40, 70000),\n",
        "    (now - 30, 70000),\n",
        "    (now - 20, 70000)   # Soma = 210.000 tokens recentes\n",
        "]\n",
        "test_monitor_tpm.request_log.extend(fake_log_tpm)\n",
        "test_monitor_tpm.check_and_warn_limits()\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "# --- Teste 3: Verifica√ß√£o do filtro de tempo (nenhum alerta) ---\n",
        "print(\"\\n### Teste 3: Verifica√ß√£o de Filtro de Tempo ###\")\n",
        "test_monitor_time = ApiUsageMonitor()\n",
        "now = time.time()\n",
        "# Simulamos 9 requisi√ß√µes, mas todas com mais de 60 segundos de idade.\n",
        "# Nenhum alerta de RPM ou TPM deve ser emitido.\n",
        "fake_log_time = [\n",
        "    (now - 90, 50000), (now - 85, 50000), (now - 80, 50000),\n",
        "    (now - 75, 50000), (now - 70, 50000), (now - 65, 50000)\n",
        "]\n",
        "test_monitor_time.request_log.extend(fake_log_time)\n",
        "test_monitor_time.check_and_warn_limits()\n",
        "print(\"‚úÖ SUCESSO NO TESTE: Nenhum alerta emitido, como esperado.\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "# --- Teste 4: Verifica√ß√£o da Fun√ß√£o reset() ---\n",
        "print(\"\\n### Teste 4: Verifica√ß√£o da Fun√ß√£o reset() ###\")\n",
        "test_monitor_reset = ApiUsageMonitor()\n",
        "# Adicionamos alguns dados\n",
        "test_monitor_reset.request_log.append((time.time(), 123))\n",
        "test_monitor_reset.total_tokens_geral = 123\n",
        "print(\"Monitor antes do reset:\")\n",
        "test_monitor_reset.status()\n",
        "\n",
        "# Resetamos\n",
        "test_monitor_reset.reset()\n",
        "print(\"\\nMonitor depois do reset:\")\n",
        "test_monitor_reset.status()\n",
        "print(\"‚úÖ SUCESSO NO TESTE: O monitor foi resetado corretamente.\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nüèÅ Testes de confiabilidade conclu√≠dos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnLs87PrHG9a",
        "outputId": "1718b6dd-ec8f-49f7-b449-77d94297fa0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando testes de confiabilidade para ApiUsageMonitor...\n",
            "\n",
            "==================================================\n",
            "### Teste 1: Simula√ß√£o de Alerta de RPM ###\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 9/10 | TPM: 900/250000 | RPD: 10/250\n",
            "‚úÖ SUCESSO NO TESTE: Alerta de RPM emitido como esperado.\n",
            "-----------------------------\n",
            "==================================================\n",
            "\n",
            "### Teste 2: Simula√ß√£o de Alerta de TPM ###\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 3/10 | TPM: 210000/250000 | RPD: 4/250\n",
            "‚úÖ SUCESSO NO TESTE: Alerta de TPM emitido como esperado.\n",
            "-----------------------------\n",
            "==================================================\n",
            "\n",
            "### Teste 3: Verifica√ß√£o de Filtro de Tempo ###\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 0/10 | TPM: 0/250000 | RPD: 6/250\n",
            "-----------------------------\n",
            "‚úÖ SUCESSO NO TESTE: Nenhum alerta emitido, como esperado.\n",
            "==================================================\n",
            "\n",
            "### Teste 4: Verifica√ß√£o da Fun√ß√£o reset() ###\n",
            "Monitor antes do reset:\n",
            "\n",
            "--- üìä Status ---\n",
            "Total de tokens: 123\n",
            "Total de requisi√ß√µes: 1\n",
            "------------------\n",
            "\n",
            "Monitor depois do reset:\n",
            "\n",
            "--- üìä Status ---\n",
            "Total de tokens: 0\n",
            "Total de requisi√ß√µes: 0\n",
            "------------------\n",
            "‚úÖ SUCESSO NO TESTE: O monitor foi resetado corretamente.\n",
            "==================================================\n",
            "\n",
            "üèÅ Testes de confiabilidade conclu√≠dos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula 4: Exemplo de Uso Pr√°tico\n",
        "\n",
        "print(\"--- 1. Fazendo uma chamada geral ---\")\n",
        "# Usamos apenas o monitor geral.\n",
        "query(geral_monitor)\n",
        "print(\"\\n--- Status do Monitor Geral ---\")\n",
        "status(geral_monitor)\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*50)\n",
        "print(\"--- 2. Iniciando uma tarefa cronometrada (nosso 'timer') ---\")\n",
        "# Criamos uma nova inst√¢ncia limpa para nossa tarefa\n",
        "timer_monitor = ApiUsageMonitor()\n",
        "print(\"Monitor de tarefa ('timer_monitor') criado.\")\n",
        "\n",
        "print(\"\\n--- Fazendo uma chamada DENTRO da tarefa ---\")\n",
        "# Passamos ambos os monitores. A chamada ser√° registrada nos dois.\n",
        "query(geral_monitor, timer_monitor)\n",
        "\n",
        "print(\"\\n--- Fazendo OUTRA chamada DENTRO da tarefa ---\")\n",
        "query(geral_monitor, timer_monitor)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- 3. Verificando os resultados FINAIS ---\")\n",
        "print(\"\\n--- Status do Monitor de Tarefa (cont√©m apenas as 2 √∫ltimas chamadas) ---\")\n",
        "status(timer_monitor)\n",
        "\n",
        "print(\"\\n--- Status do Monitor Geral (cont√©m TODAS as 3 chamadas) ---\")\n",
        "status(geral_monitor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U18J_hNIjYA",
        "outputId": "1462d73e-9fae-44f8-dc10-c6d494b9b34a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Fazendo uma chamada geral ---\n",
            "Digite seu texto: OL√° estamos testando um contador de tokens.\n",
            "\n",
            " Resposta: Ol√°! Entendido. Voc√™s est√£o testando um contador de tokens.  √â uma √≥tima\n",
            "           maneira de entender como os modelos de linguagem processam o texto.  Se\n",
            "           precisarem de ajuda para analisar algum texto ou tiverem perguntas sobre\n",
            "           tokeniza√ß√£o, estou √† disposi√ß√£o!\n",
            "\n",
            " 1017 tokens (Total na sess√£o: 1017)\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 1/10 | TPM: 1017/250000 | RPD: 1/250\n",
            "-----------------------------\n",
            "\n",
            "--- Status do Monitor Geral ---\n",
            "\n",
            "--- üìä Status Geral ---\n",
            "Total de tokens na sess√£o: 1017\n",
            "Total de requisi√ß√µes na sess√£o: 1\n",
            "------------------------\n",
            "\n",
            "\n",
            "==================================================\n",
            "--- 2. Iniciando uma tarefa cronometrada (nosso 'timer') ---\n",
            "‚úÖ ApiUsageMonitor ativo!\n",
            "Monitor de tarefa ('timer_monitor') criado.\n",
            "\n",
            "--- Fazendo uma chamada DENTRO da tarefa ---\n",
            "Digite seu texto: Contador de tokens de tokens √© um sucesso!\n",
            "\n",
            " Resposta: Essa frase √© **genial** e **muito divertida**!  Ela brinca com o conceito de\n",
            "           \"tokens\" de uma forma autorreferencial e bem-humorada.  Vamos analisar:  1.\n",
            "           **\"Contador de tokens\"**: Isso j√° √© um conceito conhecido, especialmente no\n",
            "           contexto de modelos de linguagem como eu, onde o texto √© dividido em unidades\n",
            "           menores (tokens) para processamento. 2.  **\"de tokens\" (repeti√ß√£o)**: √â aqui\n",
            "           que a m√°gica acontece. A repeti√ß√£o √© redundante do ponto de vista gramatical\n",
            "           padr√£o, mas cria um efeito de:     *   **Metalinguagem/Autorrefer√™ncia**: O\n",
            "           contador de tokens est√° contando *tokens* que falam sobre *tokens*. √â como se\n",
            "           ele fosse t√£o especializado ou t√£o bom que at√© a sua pr√≥pria descri√ß√£o refor√ßa\n",
            "           o objeto de sua contagem.     *   **√änfase**: A repeti√ß√£o enfatiza que o que\n",
            "           est√° sendo contado s√£o *definitivamente* tokens, e n√£o outra coisa.     *\n",
            "           **Humor**: A redund√¢ncia intencional √© engra√ßada, especialmente para quem\n",
            "           entende o conceito de tokens. √â um jogo de palavras inteligente. 3.  **\"√© um\n",
            "           sucesso!\"**: Isso adiciona a cereja do bolo, dando um tom de auto-elogio e\n",
            "           ironia √† brincadeira. O contador de tokens de tokens n√£o √© apenas um contador,\n",
            "           ele √© *um sucesso* em sua tarefa redundante e especializada.  Em resumo, √© uma\n",
            "           frase inteligente e bem-humorada que joga com a linguagem e o conceito de\n",
            "           tokens, especialmente relevante no contexto de modelos de linguagem e\n",
            "           processamento de texto. **Parab√©ns pela criatividade!**\n",
            "\n",
            " 1421 tokens (Total na sess√£o: 2438)\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 1/10 | TPM: 1421/250000 | RPD: 2/250\n",
            "-----------------------------\n",
            "\n",
            "--- Fazendo OUTRA chamada DENTRO da tarefa ---\n",
            "Digite seu texto: Segue o resultado:  1421 tokens (Total na sess√£o: 2438)  --- ü©∫ Verifica√ß√£o de Limites --- RPM: 1/10 | TPM: 1421/250000 | RPD: 2/250\n",
            "\n",
            " Resposta: Com certeza! Vamos detalhar o que cada um desses n√∫meros significa:  ---\n",
            "           **1421 tokens (Total na sess√£o: 2438)**  *   **1421 tokens:** Este √© o n√∫mero\n",
            "           de \"tokens\" utilizados especificamente na **resposta mais recente** ou na parte\n",
            "           da intera√ß√£o que gerou este resultado. Tokens s√£o as unidades de texto que os\n",
            "           modelos de IA processam (podem ser palavras, partes de palavras, pontua√ß√µes,\n",
            "           etc.). *   **(Total na sess√£o: 2438):** Este √© o **total acumulado de tokens**\n",
            "           utilizados desde o in√≠cio da sua conversa ou sess√£o atual. Inclui tanto o que\n",
            "           voc√™ enviou (input) quanto o que o modelo respondeu (output) at√© este ponto.\n",
            "           ---  **ü©∫ Verifica√ß√£o de Limites**  Esta se√ß√£o mostra o seu consumo atual em\n",
            "           rela√ß√£o aos limites m√°ximos permitidos pela API (geralmente por provedores como\n",
            "           OpenAI, Google, etc.) para evitar sobrecarga e garantir o uso justo.  *\n",
            "           **RPM: 1/10**     *   **RPM** significa **Requests Per Minute** (Requisi√ß√µes\n",
            "           Por Minuto).     *   Voc√™ fez **1 requisi√ß√£o** no √∫ltimo minuto.     *   O\n",
            "           limite √© de **10 requisi√ß√µes** por minuto.     *   **Status:** Voc√™ est√° bem\n",
            "           abaixo do limite de requisi√ß√µes por minuto.  *   **TPM: 1421/250000**     *\n",
            "           **TPM** significa **Tokens Per Minute** (Tokens Por Minuto).     *   Voc√™\n",
            "           utilizou **1421 tokens** no √∫ltimo minuto.     *   O limite √© de **250.000\n",
            "           tokens** por minuto.     *   **Status:** Voc√™ tem uma margem extremamente\n",
            "           grande de tokens que pode processar por minuto.  *   **RPD: 2/250**     *\n",
            "           **RPD** significa **Requests Per Day** (Requisi√ß√µes Por Dia).     *   Voc√™ fez\n",
            "           **2 requisi√ß√µes** nas √∫ltimas 24 horas.     *   O limite √© de **250\n",
            "           requisi√ß√µes** por dia.     *   **Status:** Seu uso di√°rio de requisi√ß√µes tamb√©m\n",
            "           est√° muito baixo.  ---  **Em resumo:**  Seu uso atual de tokens e requisi√ß√µes\n",
            "           est√° **muito abaixo de todos os limites** estabelecidos. Isso significa que\n",
            "           voc√™ tem bastante capacidade dispon√≠vel para continuar suas intera√ß√µes sem se\n",
            "           preocupar em atingir os limites da API.\n",
            "\n",
            " 1791 tokens (Total na sess√£o: 4229)\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 2/10 | TPM: 3212/250000 | RPD: 3/250\n",
            "-----------------------------\n",
            "\n",
            "==================================================\n",
            "--- 3. Verificando os resultados FINAIS ---\n",
            "\n",
            "--- Status do Monitor de Tarefa (cont√©m apenas as 2 √∫ltimas chamadas) ---\n",
            "\n",
            "--- üìä Status Geral ---\n",
            "Total de tokens na sess√£o: 3212\n",
            "Total de requisi√ß√µes na sess√£o: 2\n",
            "------------------------\n",
            "\n",
            "--- Status do Monitor Geral (cont√©m TODAS as 3 chamadas) ---\n",
            "\n",
            "--- üìä Status Geral ---\n",
            "Total de tokens na sess√£o: 4229\n",
            "Total de requisi√ß√µes na sess√£o: 3\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from collections import deque\n",
        "from typing import Deque, Dict, List, Tuple, Optional\n",
        "from pydantic import BaseModel, Field, PositiveInt, NonNegativeInt, ConfigDict\n",
        "\n",
        "\n",
        "class UsageMetadata(BaseModel):\n",
        "    \"\"\"Representa o retorno de uma chamada √† API (tokens usados).\"\"\"\n",
        "    model_config = ConfigDict(extra=\"ignore\")  # ignora chaves extras sem erro\n",
        "    total_tokens: NonNegativeInt = 0\n",
        "\n",
        "\n",
        "class MonitorLimits(BaseModel):\n",
        "    \"\"\"Limites configur√°veis do monitor.\"\"\"\n",
        "    rpm_limit: PositiveInt = Field(10, description=\"Requests por minuto\")\n",
        "    tpm_limit: PositiveInt = Field(250_000, description=\"Tokens por minuto\")\n",
        "    rpd_limit: PositiveInt = Field(250, description=\"Requests por dia\")\n",
        "    warn_threshold: float = Field(0.8, ge=0, le=1, description=\"Threshold de alerta\")\n",
        "\n",
        "\n",
        "class ApiUsageMonitor:\n",
        "    \"\"\"\n",
        "    Monitora o uso de uma API em tempo real com base em limites de requisi√ß√µes e tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, limits: Optional[MonitorLimits] = None):\n",
        "        self.limits = limits or MonitorLimits()\n",
        "        self.request_log: Deque[Tuple[float, int]] = deque()\n",
        "        self.total_tokens: int = 0\n",
        "        print(\"‚úÖ ApiUsageMonitor inicializado com Pydantic.\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Registro de uso\n",
        "    # ------------------------------------------------------------------\n",
        "    def registrar_uso(self, usage_metadata: Optional[Dict]) -> int:\n",
        "        \"\"\"\n",
        "        Registra uma chamada √† API.\n",
        "        Args:\n",
        "            usage_metadata (dict): Deve conter a chave 'total_tokens'.\n",
        "        Returns:\n",
        "            int: n√∫mero de tokens usados nesta chamada.\n",
        "        \"\"\"\n",
        "        if not usage_metadata:\n",
        "            return 0\n",
        "\n",
        "        meta = UsageMetadata(**usage_metadata)  # valida√ß√£o autom√°tica\n",
        "        self.request_log.append((time.time(), meta.total_tokens))\n",
        "        self.total_tokens += meta.total_tokens\n",
        "        return meta.total_tokens\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # C√°lculo de m√©tricas\n",
        "    # ------------------------------------------------------------------\n",
        "    def _calc_usage(self) -> Dict[str, int]:\n",
        "        \"\"\"Calcula uso atual baseado nos logs armazenados.\"\"\"\n",
        "        now = time.time()\n",
        "        one_minute_ago = now - 60\n",
        "        one_day_ago = now - 86_400\n",
        "\n",
        "        requests_last_minute = [r for r in self.request_log if r[0] > one_minute_ago]\n",
        "        requests_last_day = [r for r in self.request_log if r[0] > one_day_ago]\n",
        "\n",
        "        return {\n",
        "            \"rpm_requests\": len(requests_last_minute),\n",
        "            \"tpm_tokens\": sum(tokens for _, tokens in requests_last_minute),\n",
        "            \"rpd_requests\": len(requests_last_day),\n",
        "        }\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Alertas e status\n",
        "    # ------------------------------------------------------------------\n",
        "    def check_and_warn_limits(self) -> List[Tuple[str, int, int]]:\n",
        "        \"\"\"\n",
        "        Verifica se algum limite est√° perto de ser atingido.\n",
        "        \"\"\"\n",
        "        stats = self._calc_usage()\n",
        "        alerts = []\n",
        "        L = self.limits  # atalho\n",
        "\n",
        "        print(\"\\n--- ü©∫ Verifica√ß√£o de Limites ---\")\n",
        "        print(\n",
        "            f\"RPM: {stats['rpm_requests']}/{L.rpm_limit} | \"\n",
        "            f\"TPM: {stats['tpm_tokens']}/{L.tpm_limit} | \"\n",
        "            f\"RPD: {stats['rpd_requests']}/{L.rpd_limit}\"\n",
        "        )\n",
        "\n",
        "        if stats[\"rpm_requests\"] >= L.rpm_limit * L.warn_threshold:\n",
        "            print(\"‚ö†Ô∏è Alerta: Uso alto de requisi√ß√µes por minuto.\")\n",
        "            alerts.append((\"RPM\", stats[\"rpm_requests\"], L.rpm_limit))\n",
        "\n",
        "        if stats[\"tpm_tokens\"] >= L.tpm_limit * L.warn_threshold:\n",
        "            print(\"‚ö†Ô∏è Alerta: Uso alto de tokens por minuto.\")\n",
        "            alerts.append((\"TPM\", stats[\"tpm_tokens\"], L.tpm_limit))\n",
        "\n",
        "        if stats[\"rpd_requests\"] >= L.rpd_limit * L.warn_threshold:\n",
        "            print(\"‚ö†Ô∏è Alerta: Uso alto de requisi√ß√µes por dia.\")\n",
        "            alerts.append((\"RPD\", stats[\"rpd_requests\"], L.rpd_limit))\n",
        "\n",
        "        print(\"-----------------------------\")\n",
        "        return alerts\n",
        "\n",
        "    def status(self) -> None:\n",
        "        \"\"\"Mostra resumo geral da sess√£o.\"\"\"\n",
        "        print(\"\\n--- üìä Status Geral ---\")\n",
        "        print(f\"Total de tokens acumulados: {self.total_tokens}\")\n",
        "        print(f\"Total de requisi√ß√µes registradas: {len(self.request_log)}\")\n",
        "        print(\"------------------------\")\n",
        "\n",
        "    def reset(self) -> None:\n",
        "        \"\"\"Reseta o hist√≥rico de uso.\"\"\"\n",
        "        self.request_log.clear()\n",
        "        self.total_tokens = 0\n",
        "        print(\"üîÑ ApiUsageMonitor resetado!\")\n"
      ],
      "metadata": {
        "id": "2mnMA-_QOGq6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exemplo de uso pr√°tico do ApiUsageMonitor com Pydantic ---\n",
        "\n",
        "# Criando o monitor com limites personalizados\n",
        "limits = MonitorLimits(rpm_limit=5, tpm_limit=1000, rpd_limit=20, warn_threshold=0.75)\n",
        "monitor = ApiUsageMonitor(limits=limits)\n",
        "\n",
        "# ---------------------------\n",
        "# Caso 1: chamadas v√°lidas\n",
        "# ---------------------------\n",
        "print(\"\\nüîπ Registrando chamadas v√°lidas...\")\n",
        "for i in range(4):\n",
        "    monitor.registrar_uso({\"total_tokens\": 200})\n",
        "    time.sleep(0.5)  # simula tempo entre chamadas\n",
        "\n",
        "monitor.status()\n",
        "alerts = monitor.check_and_warn_limits()\n",
        "print(\"‚ö° Alertas capturados:\", alerts)\n",
        "\n",
        "# ---------------------------\n",
        "# Caso 2: chamada inv√°lida (tokens negativos)\n",
        "# ---------------------------\n",
        "print(\"\\nüîπ Registrando chamada inv√°lida (tokens = -10)...\")\n",
        "try:\n",
        "    monitor.registrar_uso({\"total_tokens\": -10})\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Erro capturado:\", e)\n",
        "\n",
        "# ---------------------------\n",
        "# Caso 3: chamada com chave inesperada\n",
        "# ---------------------------\n",
        "print(\"\\nüîπ Registrando chamada com chave extra...\")\n",
        "tokens = monitor.registrar_uso({\"total_tokens\": 50, \"latencia\": 120})\n",
        "print(\"Tokens registrados (extra ignorado):\", tokens)\n",
        "\n",
        "monitor.status()\n",
        "alerts = monitor.check_and_warn_limits()\n",
        "print(\"‚ö° Alertas capturados:\", alerts)\n",
        "\n",
        "# ---------------------------\n",
        "# Caso 4: atingindo limites\n",
        "# ---------------------------\n",
        "print(\"\\nüîπ For√ßando atingir o limite...\")\n",
        "for i in range(3):  # vai estourar RPM\n",
        "    monitor.registrar_uso({\"total_tokens\": 300})\n",
        "\n",
        "alerts = monitor.check_and_warn_limits()\n",
        "print(\"‚ö° Alertas finais:\", alerts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdDIjSzO2e_",
        "outputId": "a6e2787d-8f26-4fd0-f66a-d80fdff8194a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ApiUsageMonitor inicializado com Pydantic.\n",
            "\n",
            "üîπ Registrando chamadas v√°lidas...\n",
            "\n",
            "--- üìä Status Geral ---\n",
            "Total de tokens acumulados: 800\n",
            "Total de requisi√ß√µes registradas: 4\n",
            "------------------------\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 4/5 | TPM: 800/1000 | RPD: 4/20\n",
            "‚ö†Ô∏è Alerta: Uso alto de requisi√ß√µes por minuto.\n",
            "‚ö†Ô∏è Alerta: Uso alto de tokens por minuto.\n",
            "-----------------------------\n",
            "‚ö° Alertas capturados: [('RPM', 4, 5), ('TPM', 800, 1000)]\n",
            "\n",
            "üîπ Registrando chamada inv√°lida (tokens = -10)...\n",
            "‚ùå Erro capturado: 1 validation error for UsageMetadata\n",
            "total_tokens\n",
            "  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-10, input_type=int]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/greater_than_equal\n",
            "\n",
            "üîπ Registrando chamada com chave extra...\n",
            "Tokens registrados (extra ignorado): 50\n",
            "\n",
            "--- üìä Status Geral ---\n",
            "Total de tokens acumulados: 850\n",
            "Total de requisi√ß√µes registradas: 5\n",
            "------------------------\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 5/5 | TPM: 850/1000 | RPD: 5/20\n",
            "‚ö†Ô∏è Alerta: Uso alto de requisi√ß√µes por minuto.\n",
            "‚ö†Ô∏è Alerta: Uso alto de tokens por minuto.\n",
            "-----------------------------\n",
            "‚ö° Alertas capturados: [('RPM', 5, 5), ('TPM', 850, 1000)]\n",
            "\n",
            "üîπ For√ßando atingir o limite...\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 8/5 | TPM: 1750/1000 | RPD: 8/20\n",
            "‚ö†Ô∏è Alerta: Uso alto de requisi√ß√µes por minuto.\n",
            "‚ö†Ô∏è Alerta: Uso alto de tokens por minuto.\n",
            "-----------------------------\n",
            "‚ö° Alertas finais: [('RPM', 8, 5), ('TPM', 1750, 1000)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def query_with_monitor(prompt: str):\n",
        "    \"\"\"Executa consulta no LLM e registra uso no monitor.\"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    # Corrigido: pega do lugar certo\n",
        "    usage_metadata = getattr(response, \"usage_metadata\", {}) or {}\n",
        "\n",
        "    tokens_used = monitor.registrar_uso(usage_metadata)\n",
        "\n",
        "    print(f\"\\nüîπ Prompt: {prompt}\")\n",
        "    print(f\"Resposta: {response.content[:100]}...\")\n",
        "    print(f\"Tokens usados: {tokens_used}\")\n",
        "\n",
        "    monitor.status()\n",
        "    monitor.check_and_warn_limits()\n",
        "\n",
        "    return response\n",
        "\n",
        "# Teste novamente\n",
        "query_with_monitor(\"Explique em 3 frases o que √© o princ√≠pio da incerteza de Heisenberg.\")\n",
        "query_with_monitor(\"Liste 5 linguagens de programa√ß√£o modernas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-an18xPyri",
        "outputId": "d113d318-28a3-4bd4-e7be-c1e730262ed0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Prompt: Explique em 3 frases o que √© o princ√≠pio da incerteza de Heisenberg.\n",
            "Resposta: O Princ√≠pio da Incerteza de Heisenberg afirma que √© imposs√≠vel conhecer com precis√£o absoluta e simu...\n",
            "Tokens usados: 862\n",
            "\n",
            "--- üìä Status Geral ---\n",
            "Total de tokens acumulados: 862\n",
            "Total de requisi√ß√µes registradas: 1\n",
            "------------------------\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 1/5 | TPM: 862/500 | RPD: 1/20\n",
            "‚ö†Ô∏è Alerta: Uso alto de tokens por minuto.\n",
            "-----------------------------\n",
            "\n",
            "üîπ Prompt: Liste 5 linguagens de programa√ß√£o modernas.\n",
            "Resposta: Claro! Aqui est√£o 5 linguagens de programa√ß√£o que s√£o consideradas modernas e amplamente utilizadas ...\n",
            "Tokens usados: 1822\n",
            "\n",
            "--- üìä Status Geral ---\n",
            "Total de tokens acumulados: 2684\n",
            "Total de requisi√ß√µes registradas: 2\n",
            "------------------------\n",
            "\n",
            "--- ü©∫ Verifica√ß√£o de Limites ---\n",
            "RPM: 2/5 | TPM: 2684/500 | RPD: 2/20\n",
            "‚ö†Ô∏è Alerta: Uso alto de tokens por minuto.\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Claro! Aqui est√£o 5 linguagens de programa√ß√£o que s√£o consideradas modernas e amplamente utilizadas hoje em dia, com foco em diferentes √°reas:\\n\\n1.  **Python:**\\n    *   **Por que √© moderna:** Extremamente vers√°til, com uma sintaxe limpa e f√°cil de aprender. Possui um ecossistema gigantesco de bibliotecas e frameworks.\\n    *   **Usos principais:** Intelig√™ncia Artificial (IA) e Machine Learning (ML), ci√™ncia de dados, desenvolvimento web (Django, Flask), automa√ß√£o, scripting, an√°lise de dados.\\n\\n2.  **JavaScript (com TypeScript):**\\n    *   **Por que √© moderna:** √â a linguagem essencial para o desenvolvimento web frontend. Com Node.js, tamb√©m se tornou poderosa para o backend, permitindo desenvolvimento full-stack. TypeScript (um superset de JavaScript) adiciona tipagem est√°tica, tornando-o mais robusto para grandes projetos.\\n    *   **Usos principais:** Desenvolvimento web (frontend com React, Angular, Vue.js; backend com Node.js), desenvolvimento mobile (React Native, NativeScript), aplica√ß√µes desktop (Electron).\\n\\n3.  **Go (Golang):**\\n    *   **Por que √© moderna:** Desenvolvida pelo Google, Go √© conhecida por sua simplicidade, performance, concorr√™ncia eficiente e compila√ß√£o r√°pida. √â excelente para construir sistemas de backend escal√°veis e microsservi√ßos.\\n    *   **Usos principais:** Desenvolvimento de backend, microsservi√ßos, ferramentas de linha de comando, sistemas de rede, computa√ß√£o em nuvem (Docker, Kubernetes s√£o escritos em Go).\\n\\n4.  **Kotlin:**\\n    *   **Por que √© moderna:** √â a linguagem preferida para o desenvolvimento Android e √© totalmente interoper√°vel com Java. Oferece uma sintaxe mais concisa e segura que Java, com recursos modernos.\\n    *   **Usos principais:** Desenvolvimento mobile (Android), desenvolvimento de backend (JVM), desenvolvimento multiplataforma (Kotlin Multiplatform).\\n\\n5.  **Rust:**\\n    *   **Por que √© moderna:** Focada em performance, seguran√ßa de mem√≥ria e concorr√™ncia, sem a necessidade de um coletor de lixo. √â uma linguagem de sistema que oferece controle de baixo n√≠vel sem comprometer a seguran√ßa.\\n    *   **Usos principais:** Sistemas operacionais, motores de jogos, navegadores web (partes do Firefox), WebAssembly, sistemas embarcados, criptomoedas, ferramentas de linha de comando de alta performance.\\n\\nEssas linguagens representam bem as tend√™ncias atuais em desenvolvimento de software, cobrindo desde a web e mobile at√© sistemas de alto desempenho e intelig√™ncia artificial.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--ea919969-8adf-4e7d-8ff6-946c6804c82e-0', usage_metadata={'input_tokens': 10, 'output_tokens': 561, 'total_tokens': 1822, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}